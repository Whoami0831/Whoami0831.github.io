<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>HTML学习笔记 | Whoami的个人博客</title><meta name="author" content="Whoami"><meta name="copyright" content="Whoami"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="1.多线程2.多进程2.1 多进程的含义进程（Process）是具有一定独立功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配和调度的一个独立单位。 顾名思义，多进程就是启用多个进程同时运行。由于进程是线程的集合，而且进程是由一个或多个线程构成的，所以多进程的运行意味着有大于或等于进程数量的线程在运行。 2.2 Python 多进程的优势通过上一课时我们知道，由于进程中 GIL 的存在">
<meta property="og:type" content="article">
<meta property="og:title" content="HTML学习笔记">
<meta property="og:url" content="http://example.com/2022/12/06/python%E7%88%AC%E8%99%AB/index.html">
<meta property="og:site_name" content="Whoami的个人博客">
<meta property="og:description" content="1.多线程2.多进程2.1 多进程的含义进程（Process）是具有一定独立功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配和调度的一个独立单位。 顾名思义，多进程就是启用多个进程同时运行。由于进程是线程的集合，而且进程是由一个或多个线程构成的，所以多进程的运行意味着有大于或等于进程数量的线程在运行。 2.2 Python 多进程的优势通过上一课时我们知道，由于进程中 GIL 的存在">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2022-12-06T14:38:56.000Z">
<meta property="article:modified_time" content="2022-12-06T14:52:14.662Z">
<meta property="article:author" content="Whoami">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2022/12/06/python%E7%88%AC%E8%99%AB/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-12-06 22:52:14'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">3</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fas fa-heart"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Whoami的个人博客</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fas fa-heart"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">HTML学习笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-12-06T14:38:56.000Z" title="Created 2022-12-06 22:38:56">2022-12-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-12-06T14:52:14.662Z" title="Updated 2022-12-06 22:52:14">2022-12-06</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="HTML学习笔记"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="1-多线程"><a href="#1-多线程" class="headerlink" title="1.多线程"></a>1.多线程</h2><h2 id="2-多进程"><a href="#2-多进程" class="headerlink" title="2.多进程"></a>2.多进程</h2><h3 id="2-1-多进程的含义"><a href="#2-1-多进程的含义" class="headerlink" title="2.1 多进程的含义"></a>2.1 多进程的含义</h3><p>进程（Process）是具有一定独立功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配和调度的一个独立单位。</p>
<p>顾名思义，多进程就是启用多个进程同时运行。由于进程是线程的集合，而且进程是由一个或多个线程构成的，所以多进程的运行意味着有大于或等于进程数量的线程在运行。</p>
<h3 id="2-2-Python-多进程的优势"><a href="#2-2-Python-多进程的优势" class="headerlink" title="2.2 Python 多进程的优势"></a>2.2 Python 多进程的优势</h3><p>通过上一课时我们知道，由于进程中 GIL 的存在，Python 中的多线程并不能很好地发挥多核优势，一个进程中的多个线程，在同一时刻只能有一个线程运行。</p>
<p>而对于多进程来说，每个进程都有属于自己的 GIL，所以，在多核处理器下，多进程的运行是不会受 GIL 的影响的。因此，多进程能更好地发挥多核的优势。</p>
<p>当然，对于爬虫这种 IO 密集型任务来说，多线程和多进程影响差别并不大。对于计算密集型任务来说，Python 的多进程相比多线程，其多核运行效率会有成倍的提升。</p>
<p>总的来说，Python 的多进程整体来看是比多线程更有优势的。所以，在条件允许的情况下，能用多进程就尽量用多进程。</p>
<p>不过值得注意的是，由于进程是系统进行资源分配和调度的一个独立单位，所以各个进程之间的数据是无法共享的，如多个进程无法共享一个全局变量，进程之间的数据共享需要有单独的机制来实现，这在后面也会讲到。</p>
<h3 id="2-3-多进程的实现"><a href="#2-3-多进程的实现" class="headerlink" title="2.3 多进程的实现"></a>2.3 多进程的实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">index</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Process : <span class="subst">&#123;index&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):								<span class="comment"># 这里args必须是元组</span></span><br><span class="line">        p = multiprocessing.Process(target = process,args=(i,))		<span class="comment"># target表示调用对象，args表示被调用对象的位置参数元组</span></span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure>

<blockquote>
<p>cpu_count获取当前机器的核心数量</p>
<p>active_children获取当前正在运行的所有进程</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">index</span>):</span><br><span class="line">    time.sleep(index)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Process : <span class="subst">&#123;index&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        p = multiprocessing.Process(target = process,args=(i,))</span><br><span class="line">        p.start()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;CPU number:<span class="subst">&#123;multiprocessing.cpu_count()&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> multiprocessing.active_children():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Child process name: <span class="subst">&#123;p.name&#125;</span> id: <span class="subst">&#123;p.pid&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Process Ended&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-4-继承Process类"><a href="#2-4-继承Process类" class="headerlink" title="2.4 继承Process类"></a>2.4 继承Process类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyProcess</span>(<span class="title class_ inherited__">Process</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,loop</span>):</span><br><span class="line">        Process.__init__(self)</span><br><span class="line">        self.loop = loop</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):						<span class="comment"># 进程的运行必须写在run方法内</span></span><br><span class="line">        <span class="keyword">for</span> count <span class="keyword">in</span> <span class="built_in">range</span>(self.loop):</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Pid:<span class="subst">&#123;self.pid&#125;</span> LoopCount:<span class="subst">&#123;count&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,<span class="number">5</span>):</span><br><span class="line">        p = MyProcess(i)</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure>

<h3 id="2-5-守护进程"><a href="#2-5-守护进程" class="headerlink" title="2.5 守护进程"></a>2.5 守护进程</h3><p>在多进程中，同样存在守护进程的概念，如果一个进程被设置为守护进程，当父进程结束后，子进程会自动被终止，我们可以通过设置 daemon 属性来控制是否为守护进程。</p>
<p>这样可以有效防止无控制地生成子进程。这样的写法可以让我们在主进程运行结束后无需额外担心子进程是否关闭，避免了独立子进程的运行。</p>
<h3 id="2-6进程等待"><a href="#2-6进程等待" class="headerlink" title="2.6进程等待"></a>2.6进程等待</h3><p>在调用 start 和 join 方法后，父进程就可以等待所有子进程都执行完毕后，再打印出结束的结果。</p>
<p>默认情况下，join 是无限期的。也就是说，如果有子进程没有运行完毕，主进程会一直等待。这种情况下，如果子进程出现问题陷入了死循环，主进程也会无限等待下去。怎么解决这个问题呢？可以给 join 方法传递一个超时参数，代表最长等待秒数。如果子进程没有在这个指定秒数之内完成，会被强制返回，主进程不再会等待。也就是说这个参数设置了主进程等待该子进程的最长时间。</p>
<h3 id="2-7-终止进程"><a href="#2-7-终止进程" class="headerlink" title="2.7 终止进程"></a>2.7 终止进程</h3><p>通过terminate方法来终止某个子进程</p>
<p>通过is_alive方法来判断进程是否还在进行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Starting&#x27;</span>)</span><br><span class="line">    time.sleep(<span class="number">5</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Finished&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    p = multiprocessing.Process(target=process)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Before:&#x27;</span>, p, p.is_alive())</span><br><span class="line"></span><br><span class="line">    p.start()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;During:&#x27;</span>, p, p.is_alive())</span><br><span class="line"></span><br><span class="line">    p.terminate()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Terminate:&#x27;</span>, p, p.is_alive())</span><br><span class="line"></span><br><span class="line">    p.join()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Joined:&#x27;</span>, p, p.is_alive())</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Before: &lt;Process(Process-1, initial)&gt; False</span><br><span class="line">During: &lt;Process(Process-1, started)&gt; True</span><br><span class="line">Terminate: &lt;Process(Process-1, started)&gt; True</span><br><span class="line">Joined: &lt;Process(Process-1, stopped[SIGTERM])&gt; False</span><br></pre></td></tr></table></figure>

<p>在调用 terminate 方法之后，我们用 is_alive 方法获取进程的状态发现依然还是运行状态。在调用 join 方法之后，is_alive 方法获取进程的运行状态才变为终止状态。</p>
<p>所以，在调用 terminate 方法之后，记得要调用一下 join 方法，这里调用 join 方法可以为进程提供时间来更新对象状态，用来反映出最终的进程终止效果。</p>
<h3 id="2-8-进程互斥锁"><a href="#2-8-进程互斥锁" class="headerlink" title="2.8 进程互斥锁"></a>2.8 进程互斥锁</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process,Lock</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyProcess</span>(<span class="title class_ inherited__">Process</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,loop,lock</span>):</span><br><span class="line">        Process.__init__(self)</span><br><span class="line">        self.loop = loop</span><br><span class="line">        self.lock = lock</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> count <span class="keyword">in</span> <span class="built_in">range</span>(self.loop):</span><br><span class="line">            time.sleep(<span class="number">0.1</span>)</span><br><span class="line">            <span class="comment"># self.lock.acquire()</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;PID:<span class="subst">&#123;self.pid&#125;</span> LoopCount:<span class="subst">&#123;count&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="comment"># self.lock.release()</span></span><br><span class="line">            </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    lock = Lock()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>,<span class="number">15</span>):</span><br><span class="line">        p = MyProcess(i,lock)</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure>

<p>所以，在访问一些临界区资源时，使用 Lock 可以有效避免进程同时占用资源而导致的一些问题。</p>
<h3 id="2-9-信号量"><a href="#2-9-信号量" class="headerlink" title="2.9 信号量"></a>2.9 信号量</h3><p>信号量是进程同步过程中一个比较重要的角色</p>
<p>可以控制临界资源的数量</p>
<p>实现多个进程同时访问共享资源，限制进程的并发量</p>
<p>可以使用multiprocessing库中的Semaphore来实现信号量</p>
<h3 id="2-10-进程池"><a href="#2-10-进程池" class="headerlink" title="2.10 进程池"></a>2.10 进程池</h3><p>Pool 可以提供指定数量的进程，供用户调用，当有新的请求提交到 pool 中时，如果池还没有满，就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到规定最大值，那么该请求就会等待，直到池中有进程结束，才会创建新的进程来执行它。</p>
<p>我们用一个实例来实现一下，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">function</span>(<span class="params">index</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;start process:<span class="subst">&#123;index&#125;</span>&quot;</span>)</span><br><span class="line">    time.sleep(<span class="number">3</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;end process:<span class="subst">&#123;index&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    pool = Pool(processes = <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        pool.apply_async(function,args=(i,))	<span class="comment">#使用apply_async将进程加入到进程池中</span></span><br><span class="line">        </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;main process started&quot;</span>)</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;main process ended&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>最后，我们要记得调用 close 方法来关闭进程池，使其不再接受新的任务，然后调用 join 方法让主进程等待子进程的退出，等子进程运行完毕之后，主进程接着运行并结束。</p>
<h3 id="2-11-简化进程池，map方法的使用"><a href="#2-11-简化进程池，map方法的使用" class="headerlink" title="2.11 简化进程池，map方法的使用"></a>2.11 简化进程池，map方法的使用</h3><p>map方法第一个参数就是要启动的进程对应的执行方法，第 2 个参数是一个可迭代对象，其中的每个元素会被传递给这个执行方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">scrape</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        urllib.request.urlopen(url)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;URL <span class="subst">&#123;url&#125;</span> Scraped&#x27;</span>)</span><br><span class="line">    <span class="keyword">except</span> (urllib.error.HTTPError, urllib.error.URLError):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;URL <span class="subst">&#123;url&#125;</span> not Scraped&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    pool = Pool(processes = <span class="number">3</span>)</span><br><span class="line">    urls = [</span><br><span class="line">        <span class="string">&#x27;https://www.baidu.com&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;http://www.meituan.com/&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;http://blog.csdn.net/&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;http://xxxyxxx.net&#x27;</span></span><br><span class="line">    ]</span><br><span class="line">    pool.<span class="built_in">map</span>(scrape, urls)</span><br><span class="line">    pool.close()</span><br></pre></td></tr></table></figure>





















<h2 id="3-requests库"><a href="#3-requests库" class="headerlink" title="3.requests库"></a>3.requests库</h2><h3 id="3-1-respone对象可调用方法"><a href="#3-1-respone对象可调用方法" class="headerlink" title="3.1 respone对象可调用方法"></a>3.1 respone对象可调用方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">&#x27;http://httpbin.org/get&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.text))	<span class="comment"># 类型为str</span></span><br><span class="line"><span class="built_in">print</span>(r.json())	<span class="comment"># 返回结果为JSON格式的字典</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.json())) <span class="comment"># 类型为字典</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可知，调用json方法可以将json格式的字符串转换为字典</span></span><br></pre></td></tr></table></figure>



<h3 id="3-2-抓取二进制数据"><a href="#3-2-抓取二进制数据" class="headerlink" title="3.2 抓取二进制数据"></a>3.2 抓取二进制数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://github.com/favicon.ico&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(r.text)	<span class="comment"># str类型的数据，将图片转换为字符串会直接乱码</span></span><br><span class="line"><span class="built_in">print</span>(r.content)	<span class="comment"># 结果前带一个b 代表是bytes类型的数据</span></span><br></pre></td></tr></table></figure>

<p>将上面得到的数据保存下来，即：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://github.com/favicon.ico&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;favicon.ico&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:	<span class="comment"># 第一个参数为文件名称，第二个参数为打开方式，即以二进制的形式打开</span></span><br><span class="line">    f.write(r.content)</span><br></pre></td></tr></table></figure>



<h3 id="3-3-响应"><a href="#3-3-响应" class="headerlink" title="3.3 响应"></a>3.3 响应</h3><p>有许多属性和方法可以用来获得许多其他的信息，比如状态码，响应头，cookies等，即：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://static1.scrape.center/&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.status_code), r.status_code)	<span class="comment"># int类型，返回状态码</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.headers), r.headers)	<span class="comment">#CaseInsensitiveDict类型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.cookies), r.cookies)	<span class="comment">#RequestsCookieJar类型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.url), r.url)	<span class="comment">#str类型，返回url</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.history), r.history)	<span class="comment">#list类型，返回请求历史</span></span><br></pre></td></tr></table></figure>

<p>requests还提供了一个内置的状态码查询对象requests.codes，用法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://static1.scrape.center/&#x27;</span>)</span><br><span class="line">exit() <span class="keyword">if</span> <span class="keyword">not</span> r.status_code == requests.codes.ok <span class="keyword">else</span> <span class="built_in">print</span>(<span class="string">&#x27;Request Successfully&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>下面列出了返回码和相应的查询条件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 信息性状态码</span></span><br><span class="line"><span class="number">100</span>: (<span class="string">&#x27;continue&#x27;</span>,),</span><br><span class="line"><span class="number">101</span>: (<span class="string">&#x27;switching_protocols&#x27;</span>,),</span><br><span class="line"><span class="number">102</span>: (<span class="string">&#x27;processing&#x27;</span>,),</span><br><span class="line"><span class="number">103</span>: (<span class="string">&#x27;checkpoint&#x27;</span>,),</span><br><span class="line"><span class="number">122</span>: (<span class="string">&#x27;uri_too_long&#x27;</span>, <span class="string">&#x27;request_uri_too_long&#x27;</span>),</span><br><span class="line"></span><br><span class="line"><span class="comment"># 成功状态码</span></span><br><span class="line"><span class="number">200</span>: (<span class="string">&#x27;ok&#x27;</span>, <span class="string">&#x27;okay&#x27;</span>, <span class="string">&#x27;all_ok&#x27;</span>, <span class="string">&#x27;all_okay&#x27;</span>, <span class="string">&#x27;all_good&#x27;</span>, <span class="string">&#x27;\\o/&#x27;</span>, <span class="string">&#x27;✓&#x27;</span>),</span><br><span class="line"><span class="number">201</span>: (<span class="string">&#x27;created&#x27;</span>,),</span><br><span class="line"><span class="number">202</span>: (<span class="string">&#x27;accepted&#x27;</span>,),</span><br><span class="line"><span class="number">203</span>: (<span class="string">&#x27;non_authoritative_info&#x27;</span>, <span class="string">&#x27;non_authoritative_information&#x27;</span>),</span><br><span class="line"><span class="number">204</span>: (<span class="string">&#x27;no_content&#x27;</span>,),</span><br><span class="line"><span class="number">205</span>: (<span class="string">&#x27;reset_content&#x27;</span>, <span class="string">&#x27;reset&#x27;</span>),</span><br><span class="line"><span class="number">206</span>: (<span class="string">&#x27;partial_content&#x27;</span>, <span class="string">&#x27;partial&#x27;</span>),</span><br><span class="line"><span class="number">207</span>: (<span class="string">&#x27;multi_status&#x27;</span>, <span class="string">&#x27;multiple_status&#x27;</span>, <span class="string">&#x27;multi_stati&#x27;</span>, <span class="string">&#x27;multiple_stati&#x27;</span>),</span><br><span class="line"><span class="number">208</span>: (<span class="string">&#x27;already_reported&#x27;</span>,),</span><br><span class="line"><span class="number">226</span>: (<span class="string">&#x27;im_used&#x27;</span>,),</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重定向状态码</span></span><br><span class="line"><span class="number">300</span>: (<span class="string">&#x27;multiple_choices&#x27;</span>,),</span><br><span class="line"><span class="number">301</span>: (<span class="string">&#x27;moved_permanently&#x27;</span>, <span class="string">&#x27;moved&#x27;</span>, <span class="string">&#x27;\\o-&#x27;</span>),</span><br><span class="line"><span class="number">302</span>: (<span class="string">&#x27;found&#x27;</span>,),</span><br><span class="line"><span class="number">303</span>: (<span class="string">&#x27;see_other&#x27;</span>, <span class="string">&#x27;other&#x27;</span>),</span><br><span class="line"><span class="number">304</span>: (<span class="string">&#x27;not_modified&#x27;</span>,),</span><br><span class="line"><span class="number">305</span>: (<span class="string">&#x27;use_proxy&#x27;</span>,),</span><br><span class="line"><span class="number">306</span>: (<span class="string">&#x27;switch_proxy&#x27;</span>,),</span><br><span class="line"><span class="number">307</span>: (<span class="string">&#x27;temporary_redirect&#x27;</span>, <span class="string">&#x27;temporary_moved&#x27;</span>, <span class="string">&#x27;temporary&#x27;</span>),</span><br><span class="line"><span class="number">308</span>: (<span class="string">&#x27;permanent_redirect&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;resume_incomplete&#x27;</span>, <span class="string">&#x27;resume&#x27;</span>,), <span class="comment"># These 2 to be removed in 3.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 客户端错误状态码</span></span><br><span class="line"><span class="number">400</span>: (<span class="string">&#x27;bad_request&#x27;</span>, <span class="string">&#x27;bad&#x27;</span>),</span><br><span class="line"><span class="number">401</span>: (<span class="string">&#x27;unauthorized&#x27;</span>,),</span><br><span class="line"><span class="number">402</span>: (<span class="string">&#x27;payment_required&#x27;</span>, <span class="string">&#x27;payment&#x27;</span>),</span><br><span class="line"><span class="number">403</span>: (<span class="string">&#x27;forbidden&#x27;</span>,),</span><br><span class="line"><span class="number">404</span>: (<span class="string">&#x27;not_found&#x27;</span>, <span class="string">&#x27;-o-&#x27;</span>),</span><br><span class="line"><span class="number">405</span>: (<span class="string">&#x27;method_not_allowed&#x27;</span>, <span class="string">&#x27;not_allowed&#x27;</span>),</span><br><span class="line"><span class="number">406</span>: (<span class="string">&#x27;not_acceptable&#x27;</span>,),</span><br><span class="line"><span class="number">407</span>: (<span class="string">&#x27;proxy_authentication_required&#x27;</span>, <span class="string">&#x27;proxy_auth&#x27;</span>, <span class="string">&#x27;proxy_authentication&#x27;</span>),</span><br><span class="line"><span class="number">408</span>: (<span class="string">&#x27;request_timeout&#x27;</span>, <span class="string">&#x27;timeout&#x27;</span>),</span><br><span class="line"><span class="number">409</span>: (<span class="string">&#x27;conflict&#x27;</span>,),</span><br><span class="line"><span class="number">410</span>: (<span class="string">&#x27;gone&#x27;</span>,),</span><br><span class="line"><span class="number">411</span>: (<span class="string">&#x27;length_required&#x27;</span>,),</span><br><span class="line"><span class="number">412</span>: (<span class="string">&#x27;precondition_failed&#x27;</span>, <span class="string">&#x27;precondition&#x27;</span>),</span><br><span class="line"><span class="number">413</span>: (<span class="string">&#x27;request_entity_too_large&#x27;</span>,),</span><br><span class="line"><span class="number">414</span>: (<span class="string">&#x27;request_uri_too_large&#x27;</span>,),</span><br><span class="line"><span class="number">415</span>: (<span class="string">&#x27;unsupported_media_type&#x27;</span>, <span class="string">&#x27;unsupported_media&#x27;</span>, <span class="string">&#x27;media_type&#x27;</span>),</span><br><span class="line"><span class="number">416</span>: (<span class="string">&#x27;requested_range_not_satisfiable&#x27;</span>, <span class="string">&#x27;requested_range&#x27;</span>, <span class="string">&#x27;range_not_satisfiable&#x27;</span>),</span><br><span class="line"><span class="number">417</span>: (<span class="string">&#x27;expectation_failed&#x27;</span>,),</span><br><span class="line"><span class="number">418</span>: (<span class="string">&#x27;im_a_teapot&#x27;</span>, <span class="string">&#x27;teapot&#x27;</span>, <span class="string">&#x27;i_am_a_teapot&#x27;</span>),</span><br><span class="line"><span class="number">421</span>: (<span class="string">&#x27;misdirected_request&#x27;</span>,),</span><br><span class="line"><span class="number">422</span>: (<span class="string">&#x27;unprocessable_entity&#x27;</span>, <span class="string">&#x27;unprocessable&#x27;</span>),</span><br><span class="line"><span class="number">423</span>: (<span class="string">&#x27;locked&#x27;</span>,),</span><br><span class="line"><span class="number">424</span>: (<span class="string">&#x27;failed_dependency&#x27;</span>, <span class="string">&#x27;dependency&#x27;</span>),</span><br><span class="line"><span class="number">425</span>: (<span class="string">&#x27;unordered_collection&#x27;</span>, <span class="string">&#x27;unordered&#x27;</span>),</span><br><span class="line"><span class="number">426</span>: (<span class="string">&#x27;upgrade_required&#x27;</span>, <span class="string">&#x27;upgrade&#x27;</span>),</span><br><span class="line"><span class="number">428</span>: (<span class="string">&#x27;precondition_required&#x27;</span>, <span class="string">&#x27;precondition&#x27;</span>),</span><br><span class="line"><span class="number">429</span>: (<span class="string">&#x27;too_many_requests&#x27;</span>, <span class="string">&#x27;too_many&#x27;</span>),</span><br><span class="line"><span class="number">431</span>: (<span class="string">&#x27;header_fields_too_large&#x27;</span>, <span class="string">&#x27;fields_too_large&#x27;</span>),</span><br><span class="line"><span class="number">444</span>: (<span class="string">&#x27;no_response&#x27;</span>, <span class="string">&#x27;none&#x27;</span>),</span><br><span class="line"><span class="number">449</span>: (<span class="string">&#x27;retry_with&#x27;</span>, <span class="string">&#x27;retry&#x27;</span>),</span><br><span class="line"><span class="number">450</span>: (<span class="string">&#x27;blocked_by_windows_parental_controls&#x27;</span>, <span class="string">&#x27;parental_controls&#x27;</span>),</span><br><span class="line"><span class="number">451</span>: (<span class="string">&#x27;unavailable_for_legal_reasons&#x27;</span>, <span class="string">&#x27;legal_reasons&#x27;</span>),</span><br><span class="line"><span class="number">499</span>: (<span class="string">&#x27;client_closed_request&#x27;</span>,),</span><br><span class="line"></span><br><span class="line"><span class="comment"># 服务端错误状态码</span></span><br><span class="line"><span class="number">500</span>: (<span class="string">&#x27;internal_server_error&#x27;</span>, <span class="string">&#x27;server_error&#x27;</span>, <span class="string">&#x27;/o\\&#x27;</span>, <span class="string">&#x27;✗&#x27;</span>),</span><br><span class="line"><span class="number">501</span>: (<span class="string">&#x27;not_implemented&#x27;</span>,),</span><br><span class="line"><span class="number">502</span>: (<span class="string">&#x27;bad_gateway&#x27;</span>,),</span><br><span class="line"><span class="number">503</span>: (<span class="string">&#x27;service_unavailable&#x27;</span>, <span class="string">&#x27;unavailable&#x27;</span>),</span><br><span class="line"><span class="number">504</span>: (<span class="string">&#x27;gateway_timeout&#x27;</span>,),</span><br><span class="line"><span class="number">505</span>: (<span class="string">&#x27;http_version_not_supported&#x27;</span>, <span class="string">&#x27;http_version&#x27;</span>),</span><br><span class="line"><span class="number">506</span>: (<span class="string">&#x27;variant_also_negotiates&#x27;</span>,),</span><br><span class="line"><span class="number">507</span>: (<span class="string">&#x27;insufficient_storage&#x27;</span>,),</span><br><span class="line"><span class="number">509</span>: (<span class="string">&#x27;bandwidth_limit_exceeded&#x27;</span>, <span class="string">&#x27;bandwidth&#x27;</span>),</span><br><span class="line"><span class="number">510</span>: (<span class="string">&#x27;not_extended&#x27;</span>,),</span><br><span class="line"><span class="number">511</span>: (<span class="string">&#x27;network_authentication_required&#x27;</span>, <span class="string">&#x27;network_auth&#x27;</span>, <span class="string">&#x27;network_authentication&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="3-4-高级用法"><a href="#3-4-高级用法" class="headerlink" title="3.4 高级用法"></a>3.4 高级用法</h3><h4 id="3-4-1-文件上传"><a href="#3-4-1-文件上传" class="headerlink" title="3.4.1 文件上传"></a>3.4.1 文件上传</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">files = &#123;<span class="string">&#x27;file&#x27;</span>: <span class="built_in">open</span>(<span class="string">&#x27;favicon.ico&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>)&#125;</span><br><span class="line">r = requests.post(<span class="string">&#x27;http://httpbin.org/post&#x27;</span>, files=files)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br></pre></td></tr></table></figure>

<h4 id="3-4-2-Cookies"><a href="#3-4-2-Cookies" class="headerlink" title="3.4.2 Cookies"></a>3.4.2 Cookies</h4><p>获取cookies的实例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;http://www.baidu.com&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(r.cookies)	<span class="comment"># RequestCookieJar类型</span></span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> r.cookies.items():</span><br><span class="line">    <span class="built_in">print</span>(key + <span class="string">&#x27;=&#x27;</span> + value)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#使用items方法将其转化成元组组成的列表，遍历输出每一个cookie的名称和值</span></span><br></pre></td></tr></table></figure>

<p>也可以通过cookies参数来设置cookies的信息，这里我们可以构造一个RequestsCookieJar对象，然后处理复制下来的cookies、</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line">cookies = &#x27;_octo=GH1.1.1849343058.1576602081; _ga=GA1.2.90460451.1576602111; __Host-user_session_same_site=nbDv62kHNjp4N5KyQNYZ208waeqsmNgxFnFC88rnV7gTYQw_; _device_id=a7ca73be0e8f1a81d1e2ebb5349f9075; user_session=nbDv62kHNjp4N5KyQNYZ208waeqsmNgxFnFC88rnV7gTYQw_; logged_in=yes; dotcom_user=Germey; tz=Asia%2FShanghai; has_recent_activity=1; _gat=1; _gh_sess=your_session_info&#x27;</span><br><span class="line">jar = requests.cookies.RequestsCookieJar()</span><br><span class="line">headers = &#123;</span><br><span class="line">    &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36&#x27;</span><br><span class="line">&#125;</span><br><span class="line">for cookie in cookies.split(&#x27;;&#x27;):</span><br><span class="line">    key, value = cookie.split(&#x27;=&#x27;, 1)</span><br><span class="line">    jar.set(key, value)</span><br><span class="line">r = requests.get(&#x27;https://github.com/&#x27;, cookies=jar, headers=headers)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>

<h4 id="3-4-3-Session维持"><a href="#3-4-3-Session维持" class="headerlink" title="3.4.3 Session维持"></a>3.4.3 Session维持</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">s = requests.Session()</span><br><span class="line">s.get(<span class="string">&#x27;http://httpbin.org/cookies/set/number/123456789&#x27;</span>)</span><br><span class="line">r = s.get(<span class="string">&#x27;http://httpbin.org/cookies&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br></pre></td></tr></table></figure>

<h4 id="3-4-4-SSL证书验证"><a href="#3-4-4-SSL证书验证" class="headerlink" title="3.4.4 SSL证书验证"></a>3.4.4 SSL证书验证</h4><p>如果verify参数控制是否验证证书，如果将其设置为False，在请求时就不会验证证书有效</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">response = requests.get(<span class="string">&#x27;https://static2.scrape.center/&#x27;</span>, verify=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(response.status_code)</span><br></pre></td></tr></table></figure>

<p>这样通常会警告要求指定证书，不过可以忽略这个警告</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests.packages <span class="keyword">import</span> urllib3</span><br><span class="line"></span><br><span class="line">urllib3.disable_warnings()	<span class="comment">#忽略警告</span></span><br><span class="line">response = requests.get(<span class="string">&#x27;https://static2.scrape.center&#x27;</span>, verify=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(response.status_code)</span><br></pre></td></tr></table></figure>

<h4 id="3-4-5-超时设置"><a href="#3-4-5-超时设置" class="headerlink" title="3.4.5 超时设置"></a>3.4.5 超时设置</h4><p>在本机网络状况不好或者服务器网络响应延迟甚至无响应时，我们可能会等待很久才能收到响应，甚至到最后收不到响应而报错。为了防止服务器不能及时响应，应该设置一个超时时间，即超过了这个时间还没有得到响应，那就报错。这需要用到 timeout 参数。这个时间的计算是发出请求到服务器返回响应的时间。示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>, timeout=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(r.status_code)</span><br></pre></td></tr></table></figure>

<p>实际上，请求分为两个阶段，即连接（connect）和读取（read）。</p>
<p>上面设置的 timeout 将用作连接和读取这二者的 timeout 总和。</p>
<p>如果要分别指定，就可以传入一个元组：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>, timeout=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<h4 id="3-4-6-身份认证"><a href="#3-4-6-身份认证" class="headerlink" title="3.4.6 身份认证"></a>3.4.6 身份认证</h4><p>如果网站启用了基本身份认证，英文叫作 HTTP Basic Access Authentication，它是一种用来允许网页浏览器或其他客户端程序在请求时提供用户名和口令形式的身份凭证的一种登录验证方式。</p>
<p>可以使用requests自带的身份认证功能，通过auth参数设置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests.auth <span class="keyword">import</span> HTTPBasicAuth</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://static3.scrape.center/&#x27;</span>, auth=HTTPBasicAuth(<span class="string">&#x27;admin&#x27;</span>, <span class="string">&#x27;admin&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(r.status_code)</span><br></pre></td></tr></table></figure>

<h4 id="3-4-7-代理设置"><a href="#3-4-7-代理设置" class="headerlink" title="3.4.7 代理设置"></a>3.4.7 代理设置</h4><p>有些网站在测试的时候请求几次，能正常获取内容，但是对于大规模且频繁的请求，网站可能会弹出验证码，或者跳转到登陆认证页面，也有可能封ip，导致一定时间内无法访问。</p>
<p><strong>requests的官方文档</strong></p>
<p><a target="_blank" rel="noopener" href="https://docs.python-requests.org/en/latest/">https://docs.python-requests.org/en/latest/</a></p>
<h2 id="4-Requests-PyQuery-PyMongo-基本案例实战"><a href="#4-Requests-PyQuery-PyMongo-基本案例实战" class="headerlink" title="4. Requests + PyQuery + PyMongo 基本案例实战"></a>4. Requests + PyQuery + PyMongo 基本案例实战</h2><h3 id="4-1-库引入及基础变量定义"><a href="#4-1-库引入及基础变量定义" class="headerlink" title="4.1 库引入及基础变量定义"></a>4.1 库引入及基础变量定义</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urljoin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 日志基本设置</span></span><br><span class="line">logging.basicConfig(level = logging.INFO,<span class="built_in">format</span> = <span class="string">&quot;时间:%(asctime)s - 日志等级:%(levelname)s - 日志信息:%(message)s&quot;</span>)</span><br><span class="line"></span><br><span class="line">BASIC_URL = <span class="string">&#x27;https://static1.scrape.center&#x27;</span></span><br><span class="line">TOTAL_PAGE = <span class="number">10</span></span><br></pre></td></tr></table></figure>

<h3 id="4-2-实现一个页面的爬取方法"><a href="#4-2-实现一个页面的爬取方法" class="headerlink" title="4.2 实现一个页面的爬取方法"></a>4.2 实现一个页面的爬取方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">scrape_page</span>(<span class="params">url</span>):</span><br><span class="line">    logging.INFO(<span class="string">&quot;scraping %s...&quot;</span>,url)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        respone = requests.get(url)</span><br><span class="line">        <span class="keyword">if</span> respone.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> respone.text</span><br><span class="line">        logging.error(<span class="string">&quot;get invalid status code %s while scraping %s&quot;</span>,respone.status_code,url)</span><br><span class="line">    <span class="keyword">except</span> requests.RequestException:</span><br><span class="line">        logging.error(<span class="string">&quot;error occurred while scraping %s&quot;</span>,url)</span><br></pre></td></tr></table></figure>

<h3 id="4-3-定义列表页的爬取方法"><a href="#4-3-定义列表页的爬取方法" class="headerlink" title="4.3 定义列表页的爬取方法"></a>4.3 定义列表页的爬取方法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def scrape_index(page):</span><br><span class="line">	index_url = f&quot;&#123;BASE_URL&#125;/page/&#123;page&#125;&quot;</span><br><span class="line">	return scrape_page(scrape_index)</span><br></pre></td></tr></table></figure>

<h3 id="4-4-解析列表页"><a href="#4-4-解析列表页" class="headerlink" title="4.4 解析列表页"></a>4.4 解析列表页</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_index</span>(<span class="params">html</span>):</span><br><span class="line">    doc = pq(html)</span><br><span class="line">    links = doc(<span class="string">&quot;.el-card .name&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> links.items():</span><br><span class="line">        href = link.attr(<span class="string">&quot;href&quot;</span>)</span><br><span class="line">        detail_url = urljoin(BASE_URL,href)</span><br><span class="line">        logging.INFO(<span class="string">&quot;get detail url %s&quot;</span>,detail_url)</span><br><span class="line">        <span class="keyword">yield</span> detail_url</span><br></pre></td></tr></table></figure>

<h3 id="4-5-解析详情页"><a href="#4-5-解析详情页" class="headerlink" title="4.5 解析详情页"></a>4.5 解析详情页</h3><p>详情页的爬取方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">scrape_detail</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">return</span> scrape_page(url)</span><br></pre></td></tr></table></figure>

<p>详情页的解析方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_detail</span>(<span class="params">html</span>):</span><br><span class="line">    doc = pq(html)</span><br><span class="line">    cover = doc(<span class="string">&#x27;img.cover&#x27;</span>).attr(<span class="string">&#x27;src&#x27;</span>)</span><br><span class="line">    name = doc(<span class="string">&#x27;a &gt; h2&#x27;</span>).text()</span><br><span class="line">    categories = [item.text() <span class="keyword">for</span> item <span class="keyword">in</span> doc(<span class="string">&#x27;.categories button span&#x27;</span>).items()]</span><br><span class="line">    published_at = doc(<span class="string">&#x27;.info:contains(上映)&#x27;</span>).text()</span><br><span class="line">    published_at = re.search(<span class="string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;)&#x27;</span>, published_at).group(<span class="number">1</span>) \</span><br><span class="line">        <span class="keyword">if</span> published_at <span class="keyword">and</span> re.search(<span class="string">&#x27;\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;&#x27;</span>, published_at) <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    drama = doc(<span class="string">&#x27;.drama p&#x27;</span>).text()</span><br><span class="line">    score = doc(<span class="string">&#x27;p.score&#x27;</span>).text()</span><br><span class="line">    score = <span class="built_in">float</span>(score) <span class="keyword">if</span> score <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&#x27;cover&#x27;</span>: cover,</span><br><span class="line">        <span class="string">&#x27;name&#x27;</span>: name,</span><br><span class="line">        <span class="string">&#x27;categories&#x27;</span>: categories,</span><br><span class="line">        <span class="string">&#x27;published_at&#x27;</span>: published_at,</span><br><span class="line">        <span class="string">&#x27;drama&#x27;</span>: drama,</span><br><span class="line">        <span class="string">&#x27;score&#x27;</span>: score</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-6-保存到MongoDB"><a href="#4-6-保存到MongoDB" class="headerlink" title="4.6 保存到MongoDB"></a>4.6 保存到MongoDB</h3><p>定义MongoDB的连接配置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MONGODB_CONNECTION_STRING = <span class="string">&quot;mongodb://localhost:27017&quot;</span></span><br><span class="line">MONGO_DB_NAME = <span class="string">&quot;movies&quot;</span></span><br><span class="line">MONGO_COLLECTION_NAME = <span class="string">&quot;movies&quot;</span></span><br><span class="line"></span><br><span class="line">client = pymongo.MongoClient(MONGODB_CONNECTION_STRING)</span><br><span class="line">db = client[<span class="string">&quot;movies&quot;</span>]</span><br><span class="line">collection = db[<span class="string">&quot;movies&quot;</span>]</span><br></pre></td></tr></table></figure>

<h3 id="4-7将数据保存到MongoDB"><a href="#4-7将数据保存到MongoDB" class="headerlink" title="4.7将数据保存到MongoDB"></a>4.7将数据保存到MongoDB</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def save_data(data):</span><br><span class="line">	collection.update_one(&#123;</span><br><span class="line">		&quot;name&quot;:data.get(&quot;name&quot;)</span><br><span class="line">	&#125;,&#123;</span><br><span class="line">	&quot;$set&quot;:data</span><br><span class="line">	&#125;,upsert=True)</span><br></pre></td></tr></table></figure>

<h3 id="4-8-实现main方法"><a href="#4-8-实现main方法" class="headerlink" title="4.8 实现main方法"></a>4.8 实现main方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,TOTAL_PAGE+<span class="number">1</span>):</span><br><span class="line">        index_html = scrape_index</span><br><span class="line">        detail_urls = parse_index(index_html)</span><br><span class="line">        <span class="keyword">for</span> detail_url <span class="keyword">in</span> detail_urls:</span><br><span class="line">            detail_html = scrape_detail(detail_url)</span><br><span class="line">            data = parse_detail(detail_html)</span><br><span class="line">            logging.info(<span class="string">&quot;get detail data %s&quot;</span>,data)</span><br><span class="line">            logging.info(<span class="string">&quot;saving data to mongodb&quot;</span>)</span><br><span class="line">            save_data(data)</span><br><span class="line">            logging.INFO(<span class="string">&quot;data saved successfully&quot;</span>)</span><br><span class="line">            </span><br></pre></td></tr></table></figure>

<h3 id="4-9-多进程加速"><a href="#4-9-多进程加速" class="headerlink" title="4.9 多进程加速"></a>4.9 多进程加速</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">page</span>):</span><br><span class="line">    index_html = scrape_index(page)</span><br><span class="line">    detail_urls = parse_index(index_html)</span><br><span class="line">    <span class="keyword">for</span> detail_url <span class="keyword">in</span> detail_urls:</span><br><span class="line">        detail_html = scrape_detail(detail_url)</span><br><span class="line">        data = parse_detail(detail_html)</span><br><span class="line">        logging.info(<span class="string">&quot;get detail data %s&quot;</span>,data)</span><br><span class="line">        logging.info(<span class="string">&quot;saving data to mongodb&quot;</span>)</span><br><span class="line">        save_data(data)</span><br><span class="line">        logging.INFO(<span class="string">&quot;data saved successfully&quot;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    pool = multiprocessing.Pool()</span><br><span class="line">    pages = <span class="built_in">range</span>(<span class="number">1</span>,TOTAL_PAGE + <span class="number">1</span>)</span><br><span class="line">    pool.<span class="built_in">map</span>(main,pages)</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure>

<h2 id="5-Ajax原理和解析"><a href="#5-Ajax原理和解析" class="headerlink" title="5.Ajax原理和解析"></a>5.Ajax原理和解析</h2><p>网页的原始HTML文档不会包含任何数据，数据都是通过Ajax统一加载后再呈现出来的，这样在web开发商可以做到前后端分离，并且降低服务器直接渲染页面带来的压力.</p>
<h3 id="5-1-什么是Ajax"><a href="#5-1-什么是Ajax" class="headerlink" title="5.1 什么是Ajax"></a>5.1 什么是Ajax</h3><p>Ajax，全称为 Asynchronous JavaScript and XML，即异步的 JavaScript 和 XML。它不是一门编程语言，而是利用 JavaScript 在保证页面不被刷新、页面链接不改变的情况下与服务器交换数据并更新部分网页的技术。</p>
<h3 id="5-2-基本原理"><a href="#5-2-基本原理" class="headerlink" title="5.2 基本原理"></a>5.2 基本原理</h3><ul>
<li>发送请求</li>
<li>解析内容</li>
<li>渲染网页</li>
</ul>
<h3 id="5-3-Ajax爬取案例"><a href="#5-3-Ajax爬取案例" class="headerlink" title="5.3 Ajax爬取案例"></a>5.3 Ajax爬取案例</h3><p>也就是说在 HTML 中我们只能在源码中看到引用了一些 JavaScript 和 CSS 文件，并没有观察任何有关电影数据的信息。</p>
<p>如果遇到这样的情况，说明我们现在看到的整个页面是通过 JavaScript 渲染得到的，浏览器执行了 HTML 中所引用的 JavaScript 文件，JavaScript 通过调用一些数据加载和页面渲染的方法，才最终呈现了图中所示的页面。</p>
<p>可以通过直接爬取Ajax接口获取数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                    <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;</span>)</span><br><span class="line"></span><br><span class="line">INDEX_URL = <span class="string">&#x27;https://dynamic1.scrape.center/api/movie/?limit=&#123;limit&#125;&amp;offset=&#123;offset&#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="5-3-1-实现通用的爬取方法"><a href="#5-3-1-实现通用的爬取方法" class="headerlink" title="5.3.1 实现通用的爬取方法"></a>5.3.1 实现通用的爬取方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">scrape_api</span>(<span class="params">url</span>):</span><br><span class="line">    logging.info(<span class="string">&quot;scraping %s&quot;</span>,url)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        respone = requests.get(url)</span><br><span class="line">        <span class="keyword">if</span> respone.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> respone.json()</span><br><span class="line">        logging.error(<span class="string">&#x27;get invalid status code %s while scraping %s&#x27;</span>, response.status_code, url)</span><br><span class="line">    <span class="keyword">except</span> requests.RequestException:</span><br><span class="line">        logging.error(<span class="string">&#x27;error occurred while scraping %s&#x27;</span>, url, exc_info=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h4 id="5-3-2-定义爬取列表页的方法"><a href="#5-3-2-定义爬取列表页的方法" class="headerlink" title="5.3.2 定义爬取列表页的方法"></a>5.3.2 定义爬取列表页的方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">LIMIT = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">scrape_index</span>(<span class="params">page</span>):</span><br><span class="line">    url = INDEX_URL.<span class="built_in">format</span>(limit=LIMIT, offset=LIMIT * (page - <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> scrape_api(url)</span><br></pre></td></tr></table></figure>

<h4 id="5-3-3-爬取详情页"><a href="#5-3-3-爬取详情页" class="headerlink" title="5.3.3 爬取详情页"></a>5.3.3 爬取详情页</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DETAIL_URL = <span class="string">&#x27;https://dynamic1.scrape.center/api/movie/&#123;id&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">scrape_detail</span>(<span class="params"><span class="built_in">id</span></span>):</span><br><span class="line">    url = DETAIL_URL.<span class="built_in">format</span>(<span class="built_in">id</span>=<span class="built_in">id</span>)</span><br><span class="line">    <span class="keyword">return</span> scrape_api(url)</span><br></pre></td></tr></table></figure>

<h4 id="5-3-4-分析详情数据"><a href="#5-3-4-分析详情数据" class="headerlink" title="5.3.4 分析详情数据"></a>5.3.4 分析详情数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_detail</span>(<span class="params">dic</span>):</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&quot;id&quot;</span> : dic.get(<span class="string">&quot;id&quot;</span>),</span><br><span class="line">        <span class="string">&quot;name&quot;</span> : dic.get(<span class="string">&quot;name&quot;</span>),</span><br><span class="line">        <span class="string">&quot;categories&quot;</span> : dic.get(<span class="string">&quot;categories&quot;</span>),</span><br><span class="line">        <span class="string">&quot;published_at&quot;</span> : dic.get(<span class="string">&quot;published_at&quot;</span>),</span><br><span class="line">        <span class="string">&quot;drama&quot;</span> : dic.get(<span class="string">&quot;drama&quot;</span>),</span><br><span class="line">        <span class="string">&quot;score&quot;</span> : dic.get(<span class="string">&quot;score&quot;</span>),</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>

<h4 id="5-3-5-将数据保存到MongoDB"><a href="#5-3-5-将数据保存到MongoDB" class="headerlink" title="5.3.5 将数据保存到MongoDB"></a>5.3.5 将数据保存到MongoDB</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">save_data</span>(<span class="params">data</span>):</span><br><span class="line">    collection.update_one(&#123;</span><br><span class="line">        <span class="string">&#x27;name&#x27;</span>: data.get(<span class="string">&#x27;name&#x27;</span>)</span><br><span class="line">    &#125;, &#123;</span><br><span class="line">        <span class="string">&#x27;$set&#x27;</span>: data</span><br><span class="line">    &#125;, upsert=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h4 id="5-3-6-实现主程序"><a href="#5-3-6-实现主程序" class="headerlink" title="5.3.6 实现主程序"></a>5.3.6 实现主程序</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,TOTAL_PAGE + <span class="number">1</span>):</span><br><span class="line">        index_data = scrape_index(page)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> index_data.get(<span class="string">&quot;results&quot;</span>):</span><br><span class="line">            <span class="built_in">id</span> = item.get(<span class="string">&quot;id&quot;</span>)</span><br><span class="line">            detail_data = scrape_detail(<span class="built_in">id</span>)</span><br><span class="line">            data = parse_detail(detail_data)</span><br><span class="line">            logging.info(<span class="string">&#x27;get detail data %s&#x27;</span>, data)</span><br><span class="line">            logging.info(<span class="string">&#x27;saving data to mongodb&#x27;</span>)</span><br><span class="line">            save_data(data)</span><br><span class="line">            logging.info(<span class="string">&#x27;data saved successfully&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="5-3-7-多进程加速"><a href="#5-3-7-多进程加速" class="headerlink" title="5.3.7 多进程加速"></a>5.3.7 多进程加速</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">page</span>):</span><br><span class="line">    index_data = scrape_index(page)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> index_data.get(<span class="string">&quot;results&quot;</span>):</span><br><span class="line">        <span class="built_in">id</span> = item.get(<span class="string">&quot;id&quot;</span>)</span><br><span class="line">        detail_data = scrape_detail(<span class="built_in">id</span>)</span><br><span class="line">        data = parse_detail(detail_data)</span><br><span class="line">        logging.info(<span class="string">&#x27;get detail data %s&#x27;</span>, data)</span><br><span class="line">        logging.info(<span class="string">&#x27;saving data to mongodb&#x27;</span>)</span><br><span class="line">        save_data(data)</span><br><span class="line">        logging.info(<span class="string">&#x27;data saved successfully&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pool = multiprocessing.Pool()</span><br><span class="line">    pages = <span class="built_in">range</span>(<span class="number">1</span>,TOTAL_PAGE+<span class="number">1</span>)</span><br><span class="line">    pool.<span class="built_in">map</span>(main,pages)</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure>

<h2 id="6-selenium-基本使用"><a href="#6-selenium-基本使用" class="headerlink" title="6.selenium 基本使用"></a>6.selenium 基本使用</h2><p>在某些情况下，Ajax请求的接口会包含加密的参数，如token，sign等。</p>
<p>由于接口的请求加上了 token 参数，如果不深入分析并找到 token 的构造逻辑，我们是难以直接模拟这些 Ajax 请求的。</p>
<p>此时解决方法通常有两种，一种是深挖其中的逻辑，把其中 token 的构造逻辑完全找出来，再用 Python 复现，构造 Ajax 请求；另外一种方法就是直接通过模拟浏览器的方式，绕过这个过程。因为在浏览器里面我们是可以看到这个数据的，如果能直接把看到的数据爬取下来，当然也就能获取对应的信息了。</p>
<p>ChromeDriver下载镜像网站：</p>
<p><a target="_blank" rel="noopener" href="http://npm.taobao.org/mirrors/chromedriver/">http://npm.taobao.org/mirrors/chromedriver/</a></p>
<p>安装ChormeDriver放到Chorme文件目录下</p>
<h3 id="6-1-声明浏览器对象"><a href="#6-1-声明浏览器对象" class="headerlink" title="6.1 声明浏览器对象"></a>6.1 声明浏览器对象</h3><p>使用如下方法进行初始化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">browser = webdriver.Chrome()</span><br></pre></td></tr></table></figure>

<h3 id="6-2-访问页面"><a href="#6-2-访问页面" class="headerlink" title="6.2 访问页面"></a>6.2 访问页面</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(<span class="string">&quot;https://www.taobao.com&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(browser.page_source)		<span class="comment"># 使用这个属性可以返回网页源代码</span></span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure>

<h3 id="6-3查找节点"><a href="#6-3查找节点" class="headerlink" title="6.3查找节点"></a>6.3查找节点</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com&#x27;</span>) </span><br><span class="line">input_first = browser.find_element_by_id(<span class="string">&#x27;q&#x27;</span>) </span><br><span class="line">input_second = browser.find_element_by_css_selector(<span class="string">&#x27;#q&#x27;</span>) </span><br><span class="line">input_third = browser.find_element_by_xpath(<span class="string">&#x27;//*[@id=&quot;q&quot;]&#x27;</span>) </span><br><span class="line"><span class="built_in">print</span>(input_first, input_second, input_third) </span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure>

<p><strong>多个节点</strong></p>
<p>如果在网页中只查找一个目标，那么完全可以用 find_element 方法。但如果有多个节点需要查找，再用 find_element 方法，就只能得到第 1 个节点了。如果要查找所有满足条件的节点，需要用 find_elements 这样的方法。<strong>注意，在这个方法的名称中，element 多了一个 s，注意区分。</strong></p>
<h3 id="6-4-节点交互"><a href="#6-4-节点交互" class="headerlink" title="6.4 节点交互"></a>6.4 节点交互</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver </span><br><span class="line"><span class="keyword">import</span> time </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com&#x27;</span>) </span><br><span class="line"><span class="built_in">input</span> = browser.find_element_by_id(<span class="string">&#x27;q&#x27;</span>) </span><br><span class="line"><span class="built_in">input</span>.send_keys(<span class="string">&#x27;iPhone&#x27;</span>) </span><br><span class="line">time.sleep(<span class="number">1</span>) </span><br><span class="line"><span class="built_in">input</span>.clear() </span><br><span class="line"><span class="built_in">input</span>.send_keys(<span class="string">&#x27;iPad&#x27;</span>) </span><br><span class="line">button = browser.find_element_by_class_name(<span class="string">&#x27;btn-search&#x27;</span>) </span><br><span class="line">button.click()</span><br></pre></td></tr></table></figure>

<p><strong>selenium节点交互官方文档</strong>    <a target="_blank" rel="noopener" href="http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webelement">http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webelement</a></p>
<h3 id="6-5-动作链"><a href="#6-5-动作链" class="headerlink" title="6.5 动作链"></a>6.5 动作链</h3><p>实现一个节点的拖拽动作:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver </span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ActionChains </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">url = <span class="string">&#x27;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&#x27;</span> </span><br><span class="line">browser.get(url) </span><br><span class="line">browser.switch_to.frame(<span class="string">&#x27;iframeResult&#x27;</span>) </span><br><span class="line">source = browser.find_element_by_css_selector(<span class="string">&#x27;#draggable&#x27;</span>) </span><br><span class="line">target = browser.find_element_by_css_selector(<span class="string">&#x27;#droppable&#x27;</span>) </span><br><span class="line">actions = ActionChains(browser) </span><br><span class="line">actions.drag_and_drop(source, target) </span><br><span class="line">actions.perform()</span><br></pre></td></tr></table></figure>

<p><strong>动作链文档</strong>        <a target="_blank" rel="noopener" href="http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.common.action_chains">http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.common.action_chains</a></p>
<h3 id="6-6-执行JAVASCRIPT"><a href="#6-6-执行JAVASCRIPT" class="headerlink" title="6.6 执行JAVASCRIPT"></a>6.6 执行JAVASCRIPT</h3><p>Selenium API 并没有提供实现某些操作的方法，比如，下拉进度条。但它可以直接模拟运行 JavaScript，此时使用 execute_script 方法即可实现，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.zhihu.com/explore&#x27;</span>) </span><br><span class="line">browser.execute_script(<span class="string">&#x27;window.scrollTo(0, document.body.scrollHeight)&#x27;</span>) </span><br><span class="line">browser.execute_script(<span class="string">&#x27;alert(&quot;To Bottom&quot;)&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>有了这个方法，基本上 API 没有提供的所有功能都可以用执行 JavaScript 的方式来实现了。</p>
<h3 id="6-7-获取节点信息"><a href="#6-7-获取节点信息" class="headerlink" title="6.7 获取节点信息"></a>6.7 获取节点信息</h3><h4 id="6-7-1-获得属性"><a href="#6-7-1-获得属性" class="headerlink" title="6.7.1 获得属性"></a>6.7.1 获得属性</h4><p>使用get_attribute方法来获取节点的属性，但是前提是得先选中这个节点</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">url = <span class="string">&#x27;https://dynamic2.scrape.center/&#x27;</span> </span><br><span class="line">browser.get(url)</span><br><span class="line">logo = browser.find_element_by_class_name(<span class="string">&quot;logo-image&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(logo)</span><br><span class="line"><span class="built_in">print</span>(logo.get_attribute(<span class="string">&quot;src&quot;</span>))</span><br></pre></td></tr></table></figure>

<h4 id="6-7-2-获取文本值"><a href="#6-7-2-获取文本值" class="headerlink" title="6.7.2 获取文本值"></a>6.7.2 获取文本值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver </span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">url = <span class="string">&#x27;https://dynamic2.scrape.center/&#x27;</span> </span><br><span class="line">browser.get(url)</span><br><span class="line"><span class="built_in">input</span> = browser.find_element_by_class_name(<span class="string">&#x27;logo-title&#x27;</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.text)</span><br></pre></td></tr></table></figure>

<h4 id="6-7-3-获取ID，位置，标签名，大小"><a href="#6-7-3-获取ID，位置，标签名，大小" class="headerlink" title="6.7.3 获取ID，位置，标签名，大小"></a>6.7.3 获取ID，位置，标签名，大小</h4><p>WebElement 节点还有一些其他属性，比如 id 属性可以获取节点 id，location 属性可以获取该节点在页面中的相对位置，tag_name 属性可以获取标签名称，size 属性可以获取节点的大小，也就是宽高，这些属性有时候还是很有用的。示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">url = <span class="string">&#x27;https://dynamic2.scrape.center/&#x27;</span> </span><br><span class="line">browser.get(url) </span><br><span class="line"><span class="built_in">input</span> = browser.find_element_by_class_name(<span class="string">&#x27;logo-title&#x27;</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.<span class="built_in">id</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.location) </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.tag_name) </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.size)</span><br></pre></td></tr></table></figure>

<h4 id="6-7-4-切换Frame"><a href="#6-7-4-切换Frame" class="headerlink" title="6.7.4 切换Frame"></a>6.7.4 切换Frame</h4><p>我们知道网页中有一种节点叫作 iframe，也就是子 Frame，相当于页面的子页面，它的结构和外部网页的结构完全一致。Selenium 打开页面后，默认是在父级 Frame 里面操作，而此时如果页面中还有子 Frame，Selenium 是不能获取到子 Frame 里面的节点的。这时就需要使用 switch_to.frame 方法来切换 Frame。示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time </span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver </span><br><span class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> NoSuchElementException </span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">url = <span class="string">&#x27;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&#x27;</span> </span><br><span class="line">browser.get(url) </span><br><span class="line">browser.switch_to.frame(<span class="string">&#x27;iframeResult&#x27;</span>)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    logo = browser.find_element_by_class_name(<span class="string">&#x27;logo&#x27;</span>) </span><br><span class="line"><span class="keyword">except</span> NoSuchElementException:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;NO LOGO&#x27;</span>) </span><br><span class="line">browser.switch_to.parent_frame() </span><br><span class="line">logo = browser.find_element_by_class_name(<span class="string">&#x27;logo&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(logo) </span><br><span class="line"><span class="built_in">print</span>(logo.text)</span><br></pre></td></tr></table></figure>

<h3 id="6-8-延时等待"><a href="#6-8-延时等待" class="headerlink" title="6.8 延时等待"></a>6.8 延时等待</h3><p>在 Selenium 中，get 方法会在网页框架加载结束后结束执行，此时如果获取 page_source，可能并不是浏览器完全加载完成的页面，如果某些页面有额外的 Ajax 请求，我们在网页源代码中也不一定能成功获取到。所以，这里需要延时等待一定时间，确保节点已经加载出来。</p>
<p>这里等待的方式有两种：一种是隐式等待，一种是显式等待。</p>
<h4 id="6-8-1-隐式等待"><a href="#6-8-1-隐式等待" class="headerlink" title="6.8.1 隐式等待"></a>6.8.1 隐式等待</h4><p>当使用隐式等待执行测试的时候，如果 Selenium 没有在 DOM 中找到节点，将继续等待，超出设定时间后，则抛出找不到节点的异常。换句话说，隐式等待可以在我们查找节点而节点并没有立即出现的时候，等待一段时间再查找 DOM，默认的时间是 0。示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.implicitly_wait(<span class="number">10</span>)</span><br><span class="line">browser.get(<span class="string">&quot;https://dynamic2.scrape.center/&quot;</span>)</span><br><span class="line"><span class="built_in">input</span> = browser.find_element_by_class_name(<span class="string">&#x27;logo-image&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure>

<h4 id="6-8-2-显示等待"><a href="#6-8-2-显示等待" class="headerlink" title="6.8.2 显示等待"></a>6.8.2 显示等待</h4><p>隐式等待的效果其实并没有那么好，因为我们只规定了一个固定时间，而页面的加载时间会受到网络条件的影响。</p>
<p>这里还有一种更合适的显式等待方法，它指定要查找的节点，然后指定一个最长等待时间。如果在规定时间内加载出来了这个节点，就返回查找的节点；如果到了规定时间依然没有加载出该节点，则抛出超时异常。示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.ui <span class="keyword">import</span> WebDriverWait </span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC </span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(<span class="string">&quot;https://www.taobao.com/&quot;</span>)</span><br><span class="line">wait = WebDriverWait(browser,<span class="number">10</span>)</span><br><span class="line"><span class="built_in">input</span> = wait.until(EC.presence_of_element_located((By.ID, <span class="string">&#x27;q&#x27;</span>))) 	<span class="comment"># 如果10秒内q加载出来，那么返回该节点，否则抛出异常</span></span><br><span class="line">button =  wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, <span class="string">&#x27;.btn-search&#x27;</span>)))	<span class="comment">#如果 10 秒内它是可点击的，也就代表它成功加载出来了，就会返回这个按钮节点；如果超过 10 秒还不可点击，也就是没有加载出来，就抛出异常。</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>, button)</span><br></pre></td></tr></table></figure>

<h4 id="6-8-3-所有的等待条件"><a href="#6-8-3-所有的等待条件" class="headerlink" title="6.8.3 所有的等待条件"></a>6.8.3 所有的等待条件</h4><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220506102637201.png" alt="image-20220506102637201"></p>
<p><strong>更多等待条件参数用法文档:</strong>     <a target="_blank" rel="noopener" href="http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.support.expected_conditions">http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.support.expected_conditions</a></p>
<h3 id="6-9-前进后退"><a href="#6-9-前进后退" class="headerlink" title="6.9 前进后退"></a>6.9 前进后退</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time </span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.baidu.com/&#x27;</span>) </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com/&#x27;</span>) </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.python.org/&#x27;</span>) </span><br><span class="line">browser.back() </span><br><span class="line">time.sleep(<span class="number">1</span>) </span><br><span class="line">browser.forward() </span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure>

<h3 id="6-10-Cookies"><a href="#6-10-Cookies" class="headerlink" title="6.10 Cookies"></a>6.10 Cookies</h3><p>使用selenium，对Cookies进行操作，获取，添加，删除等</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.zhihu.com/explore&#x27;</span>) </span><br><span class="line"><span class="built_in">print</span>(browser.get_cookies()) 	<span class="comment">#获取 Cookies</span></span><br><span class="line">browser.add_cookie(&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;domain&#x27;</span>: <span class="string">&#x27;www.zhihu.com&#x27;</span>, <span class="string">&#x27;value&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>&#125;) 		<span class="comment"># 添加 Cookies</span></span><br><span class="line"><span class="built_in">print</span>(browser.get_cookies()) </span><br><span class="line">browser.delete_all_cookies() 	<span class="comment">#删除 Cookies</span></span><br><span class="line"><span class="built_in">print</span>(browser.get_cookies())</span><br></pre></td></tr></table></figure>

<h3 id="6-11-选项卡管理"><a href="#6-11-选项卡管理" class="headerlink" title="6.11 选项卡管理"></a>6.11 选项卡管理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time </span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver </span><br><span class="line">browser = webdriver.Chrome() </span><br><span class="line">browser.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>) </span><br><span class="line">browser.execute_script(<span class="string">&#x27;window.open()&#x27;</span>) </span><br><span class="line"><span class="built_in">print</span>(browser.window_handles) </span><br><span class="line">browser.switch_to.window(browser.window_handles[<span class="number">1</span>])		<span class="comment"># 切换选项卡</span></span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com&#x27;</span>) </span><br><span class="line">time.sleep(<span class="number">1</span>) </span><br><span class="line">browser.switch_to.window(browser.window_handles[<span class="number">0</span>]) 	<span class="comment"># 切换选项卡</span></span><br><span class="line">browser.get(<span class="string">&#x27;https://python.org&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="6-12-异常处理"><a href="#6-12-异常处理" class="headerlink" title="6.12 异常处理"></a>6.12 异常处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver </span><br><span class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> TimeoutException, </span><br><span class="line">NoSuchElementException </span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    browser.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>) </span><br><span class="line"><span class="keyword">except</span> TimeoutException:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Time Out&#x27;</span>) </span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    browser.find_element_by_id(<span class="string">&#x27;hello&#x27;</span>) </span><br><span class="line"><span class="keyword">except</span> NoSuchElementException:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;No Element&#x27;</span>) </span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    browser.close()</span><br></pre></td></tr></table></figure>

<h3 id="6-13-反屏蔽"><a href="#6-13-反屏蔽" class="headerlink" title="6.13 反屏蔽"></a>6.13 反屏蔽</h3><p>在 Selenium 中，我们可以使用 CDP（即 Chrome Devtools-Protocol，Chrome 开发工具协议）来解决这个问题，通过 CDP 我们可以实现在每个页面刚加载的时候执行 JavaScript 代码，执行的 CDP 方法叫作 Page.addScriptToEvaluateOnNewDocument，然后传入上文的 JavaScript 代码即可，这样我们就可以在每次页面加载之前将 webdriver 属性置空了。另外我们还可以加入几个选项来隐藏 WebDriver 提示条和自动化扩展信息，代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ChromeOptions</span><br><span class="line"></span><br><span class="line">option = ChromeOptions()</span><br><span class="line">option.add_experimental_option(<span class="string">&#x27;excludeSwitches&#x27;</span>, [<span class="string">&#x27;enable-automation&#x27;</span>])</span><br><span class="line">option.add_experimental_option(<span class="string">&#x27;useAutomationExtension&#x27;</span>, <span class="literal">False</span>)</span><br><span class="line">browser = webdriver.Chrome(options=option)</span><br><span class="line">browser.execute_cdp_cmd(<span class="string">&#x27;Page.addScriptToEvaluateOnNewDocument&#x27;</span>, &#123;</span><br><span class="line">   <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;Object.defineProperty(navigator, &quot;webdriver&quot;, &#123;get: () =&gt; undefined&#125;)&#x27;</span></span><br><span class="line">&#125;)</span><br><span class="line">browser.get(<span class="string">&#x27;https://antispider1.scrape.center/&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="6-14-无头模式"><a href="#6-14-无头模式" class="headerlink" title="6.14 无头模式"></a>6.14 无头模式</h3><p>Chrome 浏览器从 60 版本已经支持了无头模式，即 Headless。无头模式在运行的时候不会再弹出浏览器窗口，减少了干扰，而且它减少了一些资源的加载，如图片等资源，所以也在一定程度上节省了资源加载时间和网络带宽。</p>
<p>我们可以借助于 ChromeOptions 来开启 Chrome Headless 模式，代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ChromeOptions</span><br><span class="line"></span><br><span class="line">option = ChromeOptions()</span><br><span class="line">option.add_argument(<span class="string">&quot;--headless&quot;</span>)</span><br><span class="line">browser = webdriver.Chrome(options=option)</span><br><span class="line">browser.set_window_size(<span class="number">1366</span>, <span class="number">768</span>)</span><br><span class="line">browser.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line">browser.get_screenshot_as_file(<span class="string">&#x27;preview.png&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="7-selenium-爬取案例"><a href="#7-selenium-爬取案例" class="headerlink" title="7. selenium 爬取案例"></a>7. selenium 爬取案例</h2><p>有的网页我们可以直接用 requests 来爬取，有的可以直接通过分析 Ajax 来爬取，不同的网站类型有其适用的爬取方法。</p>
<p>Selenium 同样也有其适用场景。对于那些带有 JavaScript 渲染的网页，我们多数情况下是无法直接用 requests 爬取网页源码的，不过在有些情况下我们可以直接用 requests 来模拟 Ajax 请求来直接得到数据。</p>
<p>然而在有些情况下 Ajax 的一些请求接口可能带有一些加密参数，如 token、sign 等等，如果不分析清楚这些参数是怎么生成的话，我们就难以模拟和构造这些参数。怎么办呢？这时候我们可以直接选择使用 Selenium 驱动浏览器渲染的方式来另辟蹊径，实现所见即所得的爬取，这样我们就无需关心在这个网页背后发生了什么请求、得到什么数据以及怎么渲染页面这些过程，我们看到的页面就是最终浏览器帮我们模拟了 Ajax 请求和 JavaScript 渲染得到的最终结果，而 Selenium 正好也能拿到这个最终结果，相当于绕过了 Ajax 请求分析和模拟的阶段，直达目标。</p>
<p>然而 Selenium 当然也有其局限性，它的爬取效率较低，有些爬取需要模拟浏览器的操作，实现相对烦琐。不过在某些场景下也不失为一种有效的爬取手段。</p>
<h3 id="7-1-抓取列表页"><a href="#7-1-抓取列表页" class="headerlink" title="7.1 抓取列表页"></a>7.1 抓取列表页</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> TimeoutException</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.wait <span class="keyword">import</span> WebDriverWait</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                   <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;</span>)</span><br><span class="line">INDEX_URL = <span class="string">&#x27;https://dynamic2.scrape.center/page/&#123;page&#125;&#x27;</span></span><br><span class="line">TIME_OUT = <span class="number">10</span></span><br><span class="line">TOTAL_PAGE = <span class="number">10</span></span><br><span class="line"><span class="comment"># 设置为headless模式 ，可以提高爬取速度</span></span><br><span class="line">options = webdriver.ChromeOptions()</span><br><span class="line">options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)</span><br><span class="line">browser = webdriver.Chrome(options=options)</span><br><span class="line">wait = WebDriverWait(browser, TIME_OUT)		<span class="comment">#设置等待时间为10秒</span></span><br></pre></td></tr></table></figure>

<h3 id="7-2-MongoDB基本配置"><a href="#7-2-MongoDB基本配置" class="headerlink" title="7.2 MongoDB基本配置"></a>7.2 MongoDB基本配置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MONGO_CONNECTION_STRING = <span class="string">&#x27;mongodb://localhost:27017&#x27;</span>   <span class="comment"># MONGO_CONNECTION_STRING：MongoDB 的连接字符串，里面定义了 MongoDB 的基本连接信息，如 host、port，还可以定义用户名密码等内容。</span></span><br><span class="line">MONGO_DB_NAME = <span class="string">&#x27;movies&#x27;</span></span><br><span class="line">MONGO_COLLECTION_NAME = <span class="string">&#x27;movies&#x27;</span></span><br><span class="line"></span><br><span class="line">client = pymongo.MongoClient(MONGO_CONNECTION_STRING)</span><br><span class="line">db = client[<span class="string">&#x27;movies&#x27;</span>]</span><br><span class="line">collection = db[<span class="string">&#x27;movies&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h3 id="7-3-定义一个通用的爬取方法"><a href="#7-3-定义一个通用的爬取方法" class="headerlink" title="7.3 定义一个通用的爬取方法"></a>7.3 定义一个通用的爬取方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">scrape_page</span>(<span class="params">url,condition,loactor</span>):</span><br><span class="line">    logging.info(<span class="string">&quot;scraping %s&quot;</span>,url)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        browser.get(url)</span><br><span class="line">        wait.until(condition(locator))</span><br><span class="line">    <span class="keyword">except</span> TimeoutException:</span><br><span class="line">        logging.error(<span class="string">&#x27;error occurred while scraping %s&#x27;</span>,url,exc_info=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h3 id="7-4-爬取列表页的方法"><a href="#7-4-爬取列表页的方法" class="headerlink" title="7.4 爬取列表页的方法"></a>7.4 爬取列表页的方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">scrape_index</span>(<span class="params">page</span>):</span><br><span class="line">    url = INDEX_URL.<span class="built_in">format</span>(page=page)</span><br><span class="line">    scrape_page(url,condition = EC.visibility_of_all_elements_located,</span><br><span class="line">    locator = (By.CSS_SELECTOR,<span class="string">&#x27;#index .item&#x27;</span>))</span><br><span class="line">    <span class="comment"># locator 代表定位器，是一个元组，它可以通过配置查询条件和参数来获取一个或多个节点，如 (By.CSS_SELECTOR, &#x27;#index .item&#x27;)  则代表通过 CSS 选择器查找 #index .item 来获取列表页所有电影信息节点</span></span><br></pre></td></tr></table></figure>

<h3 id="7-5-进行列表页的解析-（获取所有详情页的相对路径）"><a href="#7-5-进行列表页的解析-（获取所有详情页的相对路径）" class="headerlink" title="7.5 进行列表页的解析    （获取所有详情页的相对路径）"></a>7.5 进行列表页的解析    （获取所有详情页的相对路径）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_index</span>():</span><br><span class="line">    elements = browser.find_elements(By.CSS_SELECTOR,<span class="string">&#x27;#index .item .name&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> elements:</span><br><span class="line">        href = element.get_attribute(<span class="string">&quot;href&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(href)</span><br><span class="line">        <span class="keyword">yield</span> urljoin(INDEX_URL,href)</span><br></pre></td></tr></table></figure>

<h3 id="7-6爬取详情页"><a href="#7-6爬取详情页" class="headerlink" title="7.6爬取详情页"></a>7.6爬取详情页</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">scrape_detail</span>(<span class="params">url</span>):</span><br><span class="line">    scrape_page(url,condition = EC.visibility_of_element_located,</span><br><span class="line">                    locator = (By.TAG_NAME,<span class="string">&#x27;h2&#x27;</span>))    <span class="comment"># 当h2标题出现后，默认为已经加载成功</span></span><br></pre></td></tr></table></figure>

<h3 id="7-7-提取详情页"><a href="#7-7-提取详情页" class="headerlink" title="7.7 提取详情页"></a>7.7 提取详情页</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_detail</span>():</span><br><span class="line">    url=browser.current_url</span><br><span class="line">    name=browser.find_element(By.TAG_NAME,<span class="string">&#x27;h2&#x27;</span>).text</span><br><span class="line">    categories=[element.text <span class="keyword">for</span> element <span class="keyword">in</span> browser.find_elements(By.CSS_SELECTOR,<span class="string">&#x27;.categories button span&#x27;</span>)]</span><br><span class="line">    cover=browser.find_element(By.CSS_SELECTOR,<span class="string">&#x27;.cover&#x27;</span>).get_attribute(<span class="string">&#x27;src&#x27;</span>)</span><br><span class="line">    score=browser.find_element(By.CLASS_NAME,<span class="string">&#x27;score&#x27;</span>).text</span><br><span class="line">    drama=browser.find_element(By.CSS_SELECTOR,<span class="string">&#x27;.drama p&#x27;</span>).text</span><br><span class="line">    <span class="keyword">return</span>&#123;</span><br><span class="line">    <span class="string">&#x27;url&#x27;</span>:url,</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>:name,</span><br><span class="line">    <span class="string">&#x27;categories&#x27;</span>:categories,</span><br><span class="line">    <span class="string">&#x27;cover&#x27;</span>:cover,</span><br><span class="line">    <span class="string">&#x27;score&#x27;</span>:score,</span><br><span class="line">    <span class="string">&#x27;drama&#x27;</span>:drama</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h3 id="7-8-存储数据"><a href="#7-8-存储数据" class="headerlink" title="7.8 存储数据"></a>7.8 存储数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">save_data</span>(<span class="params">data</span>):</span><br><span class="line">    collection.update_one(&#123;</span><br><span class="line">        <span class="string">&#x27;name&#x27;</span>: data.get(<span class="string">&#x27;name&#x27;</span>)</span><br><span class="line">    &#125;, &#123;</span><br><span class="line">        <span class="string">&#x27;$set&#x27;</span>: data</span><br><span class="line">    &#125;, upsert=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h3 id="7-9-main方法的实现"><a href="#7-9-main方法的实现" class="headerlink" title="7.9 main方法的实现"></a>7.9 main方法的实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">page</span>):</span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">        scrape_index(page)</span><br><span class="line">        detail_urls = parse_index()</span><br><span class="line">        <span class="keyword">for</span> detail_url <span class="keyword">in</span> <span class="built_in">list</span>(detail_urls):</span><br><span class="line">            logging.info(<span class="string">&#x27;get detail url %s&#x27;</span>, detail_url)</span><br><span class="line">            scrape_detail(detail_url)</span><br><span class="line">            detail_data = parse_detail()</span><br><span class="line">            logging.info(<span class="string">&#x27;detail data %s&#x27;</span>, detail_data)</span><br><span class="line">            logging.info(<span class="string">&quot;saving data to MongoDB&quot;</span>)</span><br><span class="line">            save_data(detail_data)</span><br><span class="line">            logging.info(<span class="string">&quot;Saving Successfully&quot;</span>)</span><br><span class="line">   <span class="keyword">finally</span>:</span><br><span class="line">       browser.close()</span><br></pre></td></tr></table></figure>

<h3 id="7-10-多进程加速"><a href="#7-10-多进程加速" class="headerlink" title="7.10 多进程加速"></a>7.10 多进程加速</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pool = multiprocessing.Pool()</span><br><span class="line">    pages = <span class="built_in">range</span>(<span class="number">1</span>, TOTAL_PAGE + <span class="number">1</span>)</span><br><span class="line">    pool.<span class="built_in">map</span>(main,pages)</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure>

<h2 id="8-异步爬虫"><a href="#8-异步爬虫" class="headerlink" title="8.异步爬虫"></a>8.异步爬虫</h2><p>使用异步执行方法来加速网络爬虫，这种方法对于IO密集型任务十分有效</p>
<h3 id="8-1-阻塞"><a href="#8-1-阻塞" class="headerlink" title="8.1 阻塞"></a>8.1 阻塞</h3><p>阻塞状态指程序未得到所需计算资源时被挂起的状态。程序在等待某个操作完成期间，自身无法继续处理其他的事情，则称该程序在该操作上是阻塞的。</p>
<p>常见的阻塞形式有：网络 I/O 阻塞、磁盘 I/O 阻塞、用户输入阻塞等。阻塞是无处不在的，包括 CPU 切换上下文时，所有的进程都无法真正处理事情，它们也会被阻塞。如果是多核 CPU 则正在执行上下文切换操作的核不可被利用。</p>
<h3 id="8-2-非阻塞"><a href="#8-2-非阻塞" class="headerlink" title="8.2 非阻塞"></a>8.2 非阻塞</h3><p>程序在等待某操作过程中，自身不被阻塞，可以继续处理其他的事情，则称该程序在该操作上是非阻塞的。</p>
<p>非阻塞并不是在任何程序级别、任何情况下都可以存在的。仅当程序封装的级别可以囊括独立的子程序单元时，它才可能存在非阻塞状态。</p>
<p>非阻塞的存在是因为阻塞存在，正因为某个操作阻塞导致的耗时与效率低下，我们才要把它变成非阻塞的。</p>
<h3 id="8-3-同步"><a href="#8-3-同步" class="headerlink" title="8.3 同步"></a>8.3 同步</h3><p>不同程序单元为了完成某个任务，在执行过程中需靠某种通信方式以协调一致，我们称这些程序单元是同步执行的。</p>
<p>例如购物系统中更新商品库存，需要用“行锁”作为通信信号，让不同的更新请求强制排队顺序执行，那更新库存的操作是同步的。</p>
<p>简言之，同步意味着有序。</p>
<h3 id="8-4-异步"><a href="#8-4-异步" class="headerlink" title="8.4 异步"></a>8.4 异步</h3><p>为完成某个任务，不同程序单元之间过程中无需通信协调，也能完成任务的方式，不相关的程序单元之间可以是异步的。</p>
<p>例如，爬虫下载网页。调度程序调用下载程序后，即可调度其他任务，而无需与该下载任务保持通信以协调行为。不同网页的下载、保存等操作都是无关的，也无需相互通知协调。这些异步操作的完成时刻并不确定。</p>
<p>简言之，异步意味着无序。</p>
<h3 id="8-5-协程"><a href="#8-5-协程" class="headerlink" title="8.5 协程"></a>8.5 协程</h3><p>协程，英文叫作 Coroutine，又称微线程、纤程，协程是一种用户态的轻量级线程。</p>
<p>协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此协程能保留上一次调用时的状态，即所有局部状态的一个特定组合，每次过程重入时，就相当于进入上一次调用的状态。</p>
<p>协程本质上是个单进程，协程相对于多进程来说，无需线程上下文切换的开销，无需原子操作锁定及同步的开销，编程模型也非常简单。</p>
<p>我们可以使用协程来实现异步操作，比如在网络爬虫场景下，我们发出一个请求之后，需要等待一定的时间才能得到响应，但其实在这个等待过程中，程序可以干许多其他的事情，等到响应得到之后才切换回来继续处理，这样可以充分利用 CPU 和其他资源，这就是协程的优势。</p>
<h3 id="8-6-协程基本概念"><a href="#8-6-协程基本概念" class="headerlink" title="8.6 协程基本概念"></a>8.6 协程基本概念</h3><ul>
<li><p>event_loop:事件循环，相当于一个无限循环，我们可以把一些函数注册到这个事件循环上，当满足条件发生的时候，就会调用对应的处理方法。</p>
</li>
<li><p>coroutine:中文翻译叫协程，在 Python 中常指代为协程对象类型，我们可以将协程对象注册到时间循环中，它会被事件循环调用。我们可以使用 async 关键字来定义一个方法，这个方法在调用时不会立即被执行，而是返回一个协程对象。</p>
</li>
<li><p>task：任务，它是对协程对象的进一步封装，包含了任务的各个状态。</p>
</li>
<li><p>future：代表将来执行或没有执行的任务的结果，实际上和 task 没有本质区别。</p>
</li>
</ul>
<h3 id="8-7定义协程"><a href="#8-7定义协程" class="headerlink" title="8.7定义协程"></a>8.7定义协程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">execute</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Number:&quot;</span>,x)</span><br><span class="line">coroutine = execute(<span class="number">1</span>)	<span class="comment"># execute方法返回了一个coroutine协程对象</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Coroutine:&#x27;</span>, coroutine)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;After calling execute&#x27;</span>)</span><br><span class="line">loop = asyncio.get_event_loop()		<span class="comment">#get_event_loop方法创建一个事件循环loop</span></span><br><span class="line">loop.run_until_complete(coroutine)</span><br><span class="line"><span class="comment">#调用loop对象的run_until_complete方法将协程注册到循环coroutine中</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;After calling loop&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>在上面的例子中，当我们将 coroutine 对象传递给 run_until_complete 方法的时候，实际上它进行了一个操作就是将 coroutine 封装成了 task 对象，我们也可以显式地进行声明，如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asynico</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">execute</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Number:&quot;</span>,x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line">coroutine = execute(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Coroutine:&quot;</span>,coroutine)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;After calling execute&quot;</span>)</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">task = loop.create_task(coroutine)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line">loop.run_until_complete(task)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;After calling loop&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>另外定义 task 对象还有一种方式，就是直接通过 asyncio 的 ensure_future 方法，返回结果也是 task 对象，这样的话我们就可以不借助于 loop 来定义，即使我们还没有声明 loop 也可以提前定义好 task 对象，写法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">execute</span>(<span class="params">x</span>):</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;Number:&#x27;</span>, x)</span><br><span class="line">   <span class="keyword">return</span> x</span><br><span class="line">coroutine = execute(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Coroutine:&#x27;</span>, coroutine)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;After calling execute&#x27;</span>)</span><br><span class="line">task = asyncio.ensure_future(coroutine)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(task)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;After calling loop&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="8-8-绑定回调"><a href="#8-8-绑定回调" class="headerlink" title="8.8 绑定回调"></a>8.8 绑定回调</h3><p>另外我们也可以为某个 task 绑定一个回调方法，比如我们来看下面的例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">request</span>():</span><br><span class="line">   url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line">   status = requests.get(url)</span><br><span class="line">   <span class="keyword">return</span> status</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">callback</span>(<span class="params">task</span>):</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;Status:&#x27;</span>, task.result())</span><br><span class="line"> </span><br><span class="line">coroutine = request()</span><br><span class="line">task = asyncio.ensure_future(coroutine)</span><br><span class="line">task.add_done_callback(callback)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line"> </span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(task)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br></pre></td></tr></table></figure>

<p>当coroutine对象执行完毕之后，就去执行声明的callback方法.</p>
<p><strong>pending</strong>:悬而未决的</p>
<p>实际上不用回调方法，直接在 task 运行完毕之后也可以直接调用 result 方法获取结果，如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">request</span>():</span><br><span class="line">   url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line">   status = requests.get(url)</span><br><span class="line">   <span class="keyword">return</span> status</span><br><span class="line"> </span><br><span class="line">coroutine = request()</span><br><span class="line">task = asyncio.ensure_future(coroutine)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line"> </span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(task)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Task:&#x27;</span>, task)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Task Result:&#x27;</span>, task.result())</span><br></pre></td></tr></table></figure>

<h3 id="8-9-多任务协程"><a href="#8-9-多任务协程" class="headerlink" title="8.9 多任务协程"></a>8.9 多任务协程</h3><p>上面的例子我们只执行了一次请求，如果我们想执行多次请求应该怎么办呢？我们可以定义一个 task 列表，然后使用 asyncio 的 wait 方法即可执行:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">request</span>():</span><br><span class="line">    url = <span class="string">&quot;https://www.baidu.com&quot;</span></span><br><span class="line">    status = requests.get(url)</span><br><span class="line">    <span class="keyword">return</span> status</span><br><span class="line"></span><br><span class="line">tasks = [asyncio.ensure_future(request()) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>)]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Tasks:&quot;</span>,tasks)</span><br><span class="line"></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> task <span class="keyword">in</span> tasks:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Task Result:&quot;</span>,task.result())</span><br></pre></td></tr></table></figure>

<h3 id="8-10-协程实现"><a href="#8-10-协程实现" class="headerlink" title="8.10 协程实现"></a>8.10 协程实现</h3><p>上面的代码中，我们用一个网络请求作为示例，这就是一个耗时等待的操作，因为我们请求网页之后需要等待页面响应并返回结果。耗时等待的操作一般都是 IO 操作，比如文件读取、网络请求等等。协程对于处理这种操作是有很大优势的，当遇到需要等待的情况的时候，程序可以暂时挂起，转而去执行其他的操作，从而避免一直等待一个程序而耗费过多的时间，充分利用资源。</p>
<p>为了更好地理解协程的正确使用方法，这里我们先来看看使用协程时常犯的错误，后面再给出正确的例子来对比一下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">request</span>():</span><br><span class="line">    url = <span class="string">&quot;https://static4.scrape.center/&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Waiting for&#x27;</span>, url)</span><br><span class="line">    response = requests.get(url)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Get response from&#x27;</span>, url, <span class="string">&#x27;response&#x27;</span>, response)</span><br><span class="line">    </span><br><span class="line">    tasks = [asyncio.ensure_future(request()) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">	loop = asyncio.get_event_loop()</span><br><span class="line">	loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"> </span><br><span class="line">	end = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Cost time:&#x27;</span>, end - start)</span><br></pre></td></tr></table></figure>

<p>要实现异步，接下来我们需要了解一下 await 的用法，使用 await 可以将耗时等待的操作挂起，让出控制权。当协程执行的时候遇到 await，时间循环就会将本协程挂起，转而去执行别的协程，直到其他的协程挂起或执行完毕。</p>
<p>所以，我们可能会将代码中的 request 方法改成如下的样子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">request</span>():</span><br><span class="line">   url = <span class="string">&#x27;https://static4.scrape.center/&#x27;</span></span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;Waiting for&#x27;</span>, url)</span><br><span class="line">   response = <span class="keyword">await</span> requests.get(url)</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;Get response from&#x27;</span>, url, <span class="string">&#x27;response&#x27;</span>, response)</span><br></pre></td></tr></table></figure>

<p>根据官方文档说明，await 后面的对象必须是如下格式之一：</p>
<ul>
<li>A native coroutine object returned from a native coroutine function，一个原生 coroutine 对象。</li>
<li>A generator-based coroutine object returned from a function decorated with types.coroutine，一个由 types.coroutine 修饰的生成器，这个生成器可以返回 coroutine 对象。</li>
<li>An object with an <strong>await</strong> method returning an iterator，一个包含 <strong>await</strong> 方法的对象返回的一个迭代器。</li>
</ul>
<p>用async把请求的方法改成coroutine就可以了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"> </span><br><span class="line">start = time.time()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get</span>(<span class="params">url</span>):</span><br><span class="line">   <span class="keyword">return</span> requests.get(url)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">request</span>():</span><br><span class="line">   url = <span class="string">&#x27;https://static4.scrape.center/&#x27;</span></span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;Waiting for&#x27;</span>, url)</span><br><span class="line">   response = <span class="keyword">await</span> get(url)</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;Get response from&#x27;</span>, url, <span class="string">&#x27;response&#x27;</span>, response)</span><br><span class="line"> </span><br><span class="line">tasks = [asyncio.ensure_future(request()) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"> </span><br><span class="line">end = time.time()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Cost time:&#x27;</span>, end - start)</span><br></pre></td></tr></table></figure>

<p>它还不是异步执行，也就是说我们仅仅将涉及 IO 操作的代码封装到 async 修饰的方法里面是不可行的！我们必须要使用支持异步操作的请求方式才可以实现真正的异步，所以这里就需要 aiohttp 派上用场了。</p>
<h2 id="9-使用aiohttp"><a href="#9-使用aiohttp" class="headerlink" title="9.使用aiohttp"></a>9.使用aiohttp</h2><p>aiohttp是一个支持异步请求的库，利用它和asyncio配合我们可以非常方便的实现异步请求操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"> </span><br><span class="line">start = time.time()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get</span>(<span class="params">url</span>):</span><br><span class="line">   session = aiohttp.ClientSession()</span><br><span class="line">   response = <span class="keyword">await</span> session.get(url)</span><br><span class="line">   <span class="keyword">await</span> response.text()</span><br><span class="line">   <span class="keyword">await</span> session.close()</span><br><span class="line">   <span class="keyword">return</span> response</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">request</span>():</span><br><span class="line">   url = <span class="string">&#x27;https://static4.scrape.center/&#x27;</span></span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;Waiting for&#x27;</span>, url)</span><br><span class="line">   response = <span class="keyword">await</span> get(url)</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;Get response from&#x27;</span>, url, <span class="string">&#x27;response&#x27;</span>, response)</span><br><span class="line"> </span><br><span class="line">tasks = [asyncio.ensure_future(request()) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"> </span><br><span class="line">end = time.time()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Cost time:&#x27;</span>, end - start)</span><br></pre></td></tr></table></figure>

<p>代码里面我们使用了 await，后面跟了 get 方法，在执行这 10 个协程的时候，如果遇到了 await，那么就会将当前协程挂起，转而去执行其他的协程，直到其他的协程也挂起或执行完毕，再进行下一个协程的执行。</p>
<p>开始运行时，时间循环会运行第一个 task，针对第一个 task 来说，当执行到第一个 await 跟着的 get 方法时，它被挂起，但这个 get 方法第一步的执行是非阻塞的，挂起之后立马被唤醒，所以立即又进入执行，创建了 ClientSession 对象，接着遇到了第二个 await，调用了 session.get 请求方法，然后就被挂起了，由于请求需要耗时很久，所以一直没有被唤醒。</p>
<p>当第一个 task 被挂起了，那接下来该怎么办呢？事件循环会寻找当前未被挂起的协程继续执行，于是就转而执行第二个 task 了，也是一样的流程操作，直到执行了第十个 task 的 session.get 方法之后，全部的 task 都被挂起了。所有 task 都已经处于挂起状态，怎么办？只好等待了。5 秒之后，几个请求几乎同时都有了响应，然后几个 task 也被唤醒接着执行，输出请求结果，最后总耗时，6 秒！</p>
<p>这就是异步操作的便捷之处，当遇到阻塞式操作时，任务被挂起，程序接着去执行其他的任务，而不是傻傻地等待，这样可以充分利用 CPU 时间，而不必把时间浪费在等待 IO 上。</p>
<h3 id="9-1-aiohttp"><a href="#9-1-aiohttp" class="headerlink" title="9.1 aiohttp"></a>9.1 aiohttp</h3><p>aiohttp 是一个基于 asyncio 的异步 HTTP 网络模块，它既提供了服务端，又提供了客户端。其中我们用服务端可以搭建一个支持异步处理的服务器，用于处理请求并返回响应，类似于 Django、Flask、Tornado 等一些 Web 服务器。而客户端我们就可以用来发起请求，就类似于 requests 来发起一个 HTTP 请求然后获得响应，但 requests 发起的是同步的网络请求，而 aiohttp 则发起的是异步的。</p>
<h3 id="9-2-基本实例"><a href="#9-2-基本实例" class="headerlink" title="9.2 基本实例"></a>9.2 基本实例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asynico</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">fetch</span>(<span class="params">session,url</span>):</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> session.get(url) <span class="keyword">as</span> respone:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">await</span> respone.text(),respone.status</span><br><span class="line">    </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">        html,status = <span class="keyword">await</span> fetch(session,<span class="string">&#x27;https://cuiqingcai.com&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;html: <span class="subst">&#123;html[:<span class="number">100</span>]&#125;</span>...&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;status: <span class="subst">&#123;status&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   loop = asyncio.get_event_loop()</span><br><span class="line">   loop.run_until_complete(main())</span><br></pre></td></tr></table></figure>

<ul>
<li>在每个异步方法前面统一要加 async 来修饰。</li>
<li>with as 语句前面同样需要加 async 来修饰，在 Python 中，with as 语句用于声明一个上下文管理器，能够帮我们自动分配和释放资源，而在异步方法中，with as 前面加上 async 代表声明一个支持异步的上下文管理器。</li>
<li>对于一些返回 coroutine 的操作，前面需要加 await 来修饰，如 response 调用 text 方法，查询 API 可以发现其返回的是 coroutine 对象，那么前面就要加 await；而对于状态码来说，其返回值就是一个数值类型，那么前面就不需要加 await。所以，这里可以按照实际情况处理，参考官方文档说明，看看其对应的返回值是怎样的类型，然后决定加不加 await 就可以了。</li>
</ul>
<h3 id="9-3-post数据"><a href="#9-3-post数据" class="headerlink" title="9.3 post数据"></a>9.3 post数据</h3><p>对于 POST 表单提交，其对应的请求头的 Content-type 为 application/x-www-form-urlencoded，我们可以用如下方式来实现，代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span>&#125;</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.post(<span class="string">&#x27;https://httpbin.org/post&#x27;</span>, data=data) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="built_in">print</span>(<span class="keyword">await</span> response.text())</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<p>对于 POST JSON 数据提交，其对应的请求头的 Content-type 为 application/json，我们只需要将 post 方法的 data 参数改成 json 即可，代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span>&#125;</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.post(<span class="string">&#x27;https://httpbin.org/post&#x27;</span>, json=data) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="built_in">print</span>(<span class="keyword">await</span> response.text())</span><br></pre></td></tr></table></figure>

<h3 id="9-4-响应字段"><a href="#9-4-响应字段" class="headerlink" title="9.4 响应字段"></a>9.4 响应字段</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span>&#125;</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.post(<span class="string">&#x27;https://httpbin.org/post&#x27;</span>, data=data) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;status:&#x27;</span>, response.status)</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;headers:&#x27;</span>, response.headers)</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;body:&#x27;</span>, <span class="keyword">await</span> response.text())</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;bytes:&#x27;</span>, <span class="keyword">await</span> response.read())</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;json:&#x27;</span>, <span class="keyword">await</span> response.json())</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<h3 id="9-5-超时设置"><a href="#9-5-超时设置" class="headerlink" title="9.5 超时设置"></a>9.5 超时设置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   timeout = aiohttp.ClientTimeout(total=<span class="number">1</span>)</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession(timeout=timeout) <span class="keyword">as</span> session:</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&#x27;status:&#x27;</span>, response.status)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<h3 id="9-6-并发限制"><a href="#9-6-并发限制" class="headerlink" title="9.6 并发限制"></a>9.6 并发限制</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line">CONCURRENCY = <span class="number">5</span></span><br><span class="line">URL = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line">semaphore = asyncio.Semaphore(CONCURRENCY)</span><br><span class="line">session = <span class="literal">None</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_api</span>():</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> semaphore:</span><br><span class="line">       <span class="built_in">print</span>(<span class="string">&#x27;scraping&#x27;</span>, URL)</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.get(URL) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="keyword">await</span> asyncio.sleep(<span class="number">1</span>)</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">await</span> response.text()</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   <span class="keyword">global</span> session</span><br><span class="line">   session = aiohttp.ClientSession()</span><br><span class="line">   scrape_index_tasks = [asyncio.ensure_future(scrape_api()) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>)]</span><br><span class="line">   <span class="keyword">await</span> asyncio.gather(*scrape_index_tasks)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<p>asyncio.wait 与 asyncio.gather 异同</p>
<p><strong>相同</strong>：从功能上看，<code>asyncio.wait</code> 和 <code>asyncio.gather</code> 实现的效果是相同的，都是把所有 Task 任务结果收集起来。</p>
<p><strong>不同</strong>：<code>asyncio.wait</code> 会返回两个值：<code>done</code> 和 <code>pending</code>，<code>done</code> 为已完成的协程 <code>Task</code>，<code>pending</code> 为超时未完成的协程 <code>Task</code>，需通过 <code>future.result</code> 调用 <code>Task</code> 的 <code>result</code>；而<code>asyncio.gather</code> 返回的是所有已完成 <code>Task</code> 的 <code>result</code>，不需要再进行调用或其他操作，就可以得到全部结果。</p>
<p>作者：dex0423<br>链接：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/6872bf356af7">https://www.jianshu.com/p/6872bf356af7</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<p>**aiohttp官方文档:**<a target="_blank" rel="noopener" href="https://docs.aiohttp.org/en/stable/">https://docs.aiohttp.org/en/stable/</a></p>
<h2 id="10-aiohttp爬取实战"><a href="#10-aiohttp爬取实战" class="headerlink" title="10.aiohttp爬取实战"></a>10.aiohttp爬取实战</h2><p>爬取的网站是：<a target="_blank" rel="noopener" href="https://dynamic5.scrape.center/">https://dynamic5.scrape.center/</a></p>
<h3 id="10-1-页面分析"><a href="#10-1-页面分析" class="headerlink" title="10.1 页面分析"></a>10.1 页面分析</h3><ul>
<li><p>列表页的 Ajax 请求接口格式为：<a target="_blank" rel="noopener" href="https://dynamic5.scrape.center/api/book/?limit=18&amp;offset=%7Boffset%7D%EF%BC%8Climit">https://dynamic5.scrape.center/api/book/?limit=18&amp;offset={offset}，limit</a> 的值即为每一页的书的个数，offset 的值为每一页的偏移量，其计算公式为 offset = limit * (page - 1) ，如第 1 页 offset 的值为 0，第 2 页 offset 的值为 18，以此类推。</p>
</li>
<li><p>列表页 Ajax 接口返回的数据里 results 字段包含当前页 18 本书的信息，其中每本书的数据里面包含一个字段 id，这个 id 就是书本身的 ID，可以用来进一步请求详情页。</p>
</li>
<li><p>详情页的 Ajax 请求接口格式为：<a target="_blank" rel="noopener" href="https://dynamic5.scrape.center/api/book/%7Bid%7D%EF%BC%8Cid">https://dynamic5.scrape.center/api/book/{id}，id</a> 即为书的 ID，可以从列表页的返回结果中获取。</p>
</li>
</ul>
<h3 id="10-2-实现思路"><a href="#10-2-实现思路" class="headerlink" title="10.2 实现思路"></a>10.2 实现思路</h3><p>在这里我们将爬取的逻辑拆分成两部分，第一部分为爬取列表页，第二部分为爬取详情页。由于异步爬虫的关键点在于并发执行，所以我们可以将爬取拆分为两个阶段：</p>
<p>第一阶段为所有列表页的异步爬取，我们可以将所有的列表页的爬取任务集合起来，声明为 task 组成的列表，进行异步爬取。</p>
<p>第二阶段则是拿到上一步列表页的所有内容并解析，拿到所有书的 id 信息，组合为所有详情页的爬取任务集合，声明为 task 组成的列表，进行异步爬取，同时爬取的结果也以异步的方式存储到 MongoDB 里面。</p>
<p>因为两个阶段的拆分之后需要串行执行，所以可能不能达到协程的最佳调度方式和资源利用情况，但也差不了很多。但这个实现思路比较简单清晰，代码实现也比较简单，能够帮我们快速了解 aiohttp 的基本使用。</p>
<h3 id="10-3-基本配置"><a href="#10-3-基本配置" class="headerlink" title="10.3 基本配置"></a>10.3 基本配置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line">logging.basicConfig(level = logging.INFO,<span class="built_in">format</span> = <span class="string">&quot;%(asctime)s - %(levelname)s: %(message)s&quot;</span>)</span><br><span class="line">INDEX_URL = <span class="string">&#x27;https://dynamic5.scrape.center/api/book/?limit=18&amp;offset=&#123;offset&#125;&#x27;</span></span><br><span class="line">DETAIL_URL = <span class="string">&#x27;https://dynamic5.scrape.center/api/book/&#123;id&#125;&#x27;</span></span><br><span class="line">PAGE_SIZE = <span class="number">18</span></span><br><span class="line">PAGE_NUMBER = <span class="number">100</span></span><br><span class="line">CONCURRENCY = <span class="number">5</span></span><br></pre></td></tr></table></figure>

<h3 id="10-4-定义通用爬取方式"><a href="#10-4-定义通用爬取方式" class="headerlink" title="10.4 定义通用爬取方式"></a>10.4 定义通用爬取方式</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">semaphore = asyncio.Semaphore(CONCURRENCY)		<span class="comment"># 声明了一个信号量用来控制最大并发量</span></span><br><span class="line">session = <span class="literal">None</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_api</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> semaphore:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            logging.info(<span class="string">&quot;scraping %s&quot;</span>,url)</span><br><span class="line">            <span class="keyword">async</span> <span class="keyword">with</span> session.get(url) <span class="keyword">as</span> respone:</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">await</span> respone.json()</span><br><span class="line">            <span class="keyword">except</span> aiohttp.ClientError:</span><br><span class="line">                logging.error(<span class="string">&#x27;error occurred while scraping %s&#x27;</span>, url, exc_info=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h3 id="10-5-抓取列表页"><a href="#10-5-抓取列表页" class="headerlink" title="10.5 抓取列表页"></a>10.5 抓取列表页</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_index</span>(<span class="params">page</span>):</span><br><span class="line">    url = INDEX_URL.<span class="built_in">format</span>(offset=PAGE_SIZE * (page - <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">await</span> scrape_api(url)</span><br></pre></td></tr></table></figure>

<h3 id="10-6-获取详情页id"><a href="#10-6-获取详情页id" class="headerlink" title="10.6 获取详情页id"></a>10.6 获取详情页id</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ids = []</span><br><span class="line"><span class="keyword">for</span> index_data <span class="keyword">in</span> results:</span><br><span class="line">   <span class="keyword">if</span> <span class="keyword">not</span> index_data: <span class="keyword">continue</span></span><br><span class="line">   <span class="keyword">for</span> item <span class="keyword">in</span> index_data.get(<span class="string">&#x27;results&#x27;</span>):</span><br><span class="line">       ids.append(item.get(<span class="string">&#x27;id&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h3 id="10-7定义爬取详情页并存储方法"><a href="#10-7定义爬取详情页并存储方法" class="headerlink" title="10.7定义爬取详情页并存储方法"></a>10.7定义爬取详情页并存储方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_detail</span>(<span class="params"><span class="built_in">id</span></span>):</span><br><span class="line">   url = DETAIL_URL.<span class="built_in">format</span>(<span class="built_in">id</span>=<span class="built_in">id</span>)</span><br><span class="line">   data = <span class="keyword">await</span> scrape_api(url)</span><br><span class="line">   <span class="keyword">await</span> save_data(data)</span><br></pre></td></tr></table></figure>

<h3 id="10-8-定义存储方法"><a href="#10-8-定义存储方法" class="headerlink" title="10.8 定义存储方法"></a>10.8 定义存储方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> motor.motor_asyncio <span class="keyword">import</span> AsyncIOMotorClient</span><br><span class="line">MONGO_CONNECTION_STRING = <span class="string">&#x27;mongodb://localhost:27017&#x27;</span></span><br><span class="line">MONGO_DB_NAME = <span class="string">&#x27;books&#x27;</span></span><br><span class="line">MONGO_COLLECTION_NAME = <span class="string">&#x27;books&#x27;</span></span><br><span class="line">client = AsyncIOMotorClient(MONGO_CONNECTION_STRING)</span><br><span class="line">db = client[MONGO_DB_NAME]</span><br><span class="line">collection = db[MONGO_COLLECTION_NAME]</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">save_data</span>(<span class="params">data</span>):</span><br><span class="line">   logging.info(<span class="string">&#x27;saving data %s&#x27;</span>, data)</span><br><span class="line">   <span class="keyword">if</span> data:</span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">await</span> collection.update_one(&#123;</span><br><span class="line">           <span class="string">&#x27;id&#x27;</span>: data.get(<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">       &#125;, &#123;</span><br><span class="line">           <span class="string">&#x27;$set&#x27;</span>: data</span><br><span class="line">       &#125;, upsert=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h3 id="10-9-main方法的实现"><a href="#10-9-main方法的实现" class="headerlink" title="10.9 main方法的实现"></a>10.9 main方法的实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">global</span> session</span><br><span class="line">    session = aiohttp.ClientSession()</span><br><span class="line">    scrape_index_tasks = [asyncio.ensure_future(scrape_index(page)) <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,PAGE_NUMBER+<span class="number">1</span>)]</span><br><span class="line">    results = <span class="keyword">await</span> asyncio.gather(*scrape_index_tasks)     <span class="comment"># 所有结果都在一个列表中</span></span><br><span class="line">    logging.info(<span class="string">&#x27;results %s&#x27;</span>,json.dumps(results,ensure_ascii = <span class="literal">False</span>,indent = <span class="number">2</span>))</span><br><span class="line">    ids = []</span><br><span class="line">    <span class="keyword">for</span> index_data <span class="keyword">in</span> results:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> index_data : <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> index_data.get(<span class="string">&quot;results&quot;</span>):</span><br><span class="line">            ids.append(item.get(<span class="string">&quot;id&quot;</span>))</span><br><span class="line">    scrape_detail_tasks = [asyncio.ensure_future(scrape_detail(<span class="built_in">id</span>)) <span class="keyword">for</span> <span class="built_in">id</span> <span class="keyword">in</span> ids]</span><br><span class="line">    <span class="keyword">await</span> asyncio.wait(scrape_detail_tasks)</span><br><span class="line">    <span class="keyword">await</span> session.close()</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    asyncio.get_event_loop().run_until_complete(main())		<span class="comment"># 协程异步执行</span></span><br></pre></td></tr></table></figure>



<h2 id="11-多线程，多进程，协程异步"><a href="#11-多线程，多进程，协程异步" class="headerlink" title="11.多线程，多进程，协程异步"></a>11.多线程，多进程，协程异步</h2><ul>
<li><p> 计算机的核心是CPU，它承担了所有的计算任务。它就像一座工厂，时刻在运行。</p>
</li>
<li><p>假定工厂的电力有限，一次只能供给一个车间使用。也就是说，一个车间开工的时候，其他车间都必须停工。背后的含义就是，单个CPU一次只能运行一个任务。编者注: 多核的CPU就像有了多个发电厂，使多工厂(多进程)实现可能。</p>
</li>
<li><p>进程就好比工厂的车间，它代表CPU所能处理的单个任务。任一时刻，CPU总是运行一个进程，其他进程处于非运行状态。</p>
</li>
<li><p>一个车间里，可以有很多工人。他们协同完成一个任务。</p>
</li>
<li><p>线程就好比车间里的工人。一个进程可以包括多个线程。</p>
</li>
<li><p>车间的空间是工人们共享的，比如许多房间是每个工人都可以进出的。这象征一个进程的内存空间是共享的，每个线程都可以使用这些共享内存。</p>
</li>
<li><p>可是，每间房间的大小不同，有些房间最多只能容纳一个人，比如厕所。里面有人的时候，其他人就不能进去了。这代表一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。</p>
</li>
<li><p>一个防止他人进入的简单方法，就是门口加一把锁。先到的人锁上门，后到的人看到上锁，就在门口排队，等锁打开再进去。这就叫”互斥锁”（Mutual exclusion，缩写 Mutex），防止多个线程同时读写某一块内存区域。</p>
</li>
<li><p>还有些房间，可以同时容纳n个人，比如厨房。也就是说，如果人数大于n，多出来的人只能在外面等着。这好比某些内存区域，只能供给固定数目的线程使用。</p>
</li>
<li><p>这时的解决方法，就是在门口挂n把钥匙。进去的人就取一把钥匙，出来时再把钥匙挂回原处。后到的人发现钥匙架空了，就知道必须在门口排队等着了。这种做法叫做”信号量”（Semaphore），用来保证多个线程不会互相冲突。</p>
</li>
<li><p>不难看出，mutex是semaphore的一种特殊情况（n=1时）。也就是说，完全可以用后者替代前者。但是，因为mutex较为简单，且效率高，所以在必须保证资源独占的情况下，还是采用这种设计。</p>
<ul>
<li><p>进程是操作系统分配资源的最小单元, 线程是操作系统调度的最小单元。</p>
</li>
<li><p>一个应用程序至少包括1个进程，而1个进程包括1个或多个线程，线程的尺度更小。</p>
</li>
<li><p>每个进程在执行过程中拥有独立的内存单元，而一个线程的多个线程在执行过程中共享内存。</p>
</li>
</ul>
</li>
</ul>
<p><strong>多进程：</strong></p>
<ul>
<li>新创建的进程与进程的切换都是要耗资源的，所以平时工作中进程数不能开太大。</li>
<li>同时可以运行的进程数一般受制于CPU的核数。</li>
<li>除了使用Process方法，我们还可以使用Pool类创建多进程。</li>
</ul>
<p><strong>多线程:</strong></p>
<p>python解释器中存在GIL(全局解释器锁), 它的作用就是保证同一时刻只有一个线程可以执行代码。由于GIL的存在，很多人认为python中的多线程其实并不是真正的多线程，如果想要充分地使用多核CPU的资源，在python中大部分情况需要使用多进程。然而这并意味着python多线程编程没有意义</p>
<p>由于GIL的存在，很多人认为Python多进程编程更快，针对多核CPU，理论上来说也是采用多进程更能有效利用资源。</p>
<ul>
<li>对CPU密集型代码(比如循环计算) - 多进程效率更高</li>
<li>对IO密集型代码(比如文件操作，网络爬虫) - 多线程效率更高。</li>
</ul>
<p>进程(Process)：进程是计算机中的程序关于某数据集合的一次运行实例，是操作系统进行资源分配的最小单位</p>
<p>线程(Thread)：线程被包含在进程之中，是操作系统进行程序调度执行的最小单位</p>
<p>协程(Coroutine)：协程是用户态执行的轻量级编程模型，由单一线程内部发出控制信号进行调度</p>
<p>协程常用于IO密集型工作，例如网络资源请求等；而进程、线程常用于计算密集型工作，例如科学计算、人工神经网络等。</p>
<h2 id="12-Pyppeteer"><a href="#12-Pyppeteer" class="headerlink" title="12.Pyppeteer"></a>12.Pyppeteer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    browser = <span class="keyword">await</span> launch()</span><br><span class="line">    page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">    <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://dynamic2.scrape.center/&#x27;</span>)</span><br><span class="line">    <span class="keyword">await</span> page.waitForSelector(<span class="string">&quot;.item .name&quot;</span>)</span><br><span class="line">    doc = pq(<span class="keyword">await</span> page.content())</span><br><span class="line">    names = [item.text() <span class="keyword">for</span> item <span class="keyword">in</span> doc(<span class="string">&quot;.item .name&quot;</span>).items()]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Names:&quot;</span>,names)</span><br><span class="line">    <span class="keyword">await</span> browser.close()</span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<ul>
<li>launch 方法会新建一个 Browser 对象，其执行后最终会得到一个 Browser 对象，然后赋值给 browser。这一步就相当于启动了浏览器</li>
<li>然后 browser 调用 newPage  方法相当于浏览器中新建了一个选项卡，同时新建了一个 Page 对象，这时候新启动了一个选项卡，但是还未访问任何页面，浏览器依然是空白。</li>
<li>随后 Page 对象调用了 goto 方法就相当于在浏览器中输入了这个 URL，浏览器跳转到了对应的页面进行加载。</li>
<li>Page 对象调用 waitForSelector 方法，传入选择器，那么页面就会等待选择器所对应的节点信息加载出来，如果加载出来了，立即返回，否则会持续等待直到超时。此时如果顺利的话，页面会成功加载出来。</li>
<li>页面加载完成之后再调用 content 方法，可以获得当前浏览器页面的源代码，这就是 JavaScript 渲染后的结果。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line">width,height = <span class="number">1366</span>,<span class="number">768</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    browser = <span class="keyword">await</span> launch()</span><br><span class="line">    page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">    <span class="keyword">await</span> page.setViewport(&#123;<span class="string">&#x27;width&#x27;</span>:width,<span class="string">&#x27;height&#x27;</span>:height&#125;)</span><br><span class="line">    <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://dynamic2.scrape.center/&#x27;</span>)</span><br><span class="line">    <span class="keyword">await</span> page.waitForSelector(<span class="string">&#x27;.item .name&#x27;</span>)</span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">await</span> page.screenshot(path=<span class="string">&#x27;example.png&#x27;</span>)</span><br><span class="line">    dimensions = <span class="keyword">await</span> page.evaluate(<span class="string">&#x27;&#x27;&#x27;() =&gt; &#123;</span></span><br><span class="line"><span class="string">       return &#123;</span></span><br><span class="line"><span class="string">           width: document.documentElement.clientWidth,</span></span><br><span class="line"><span class="string">           height: document.documentElement.clientHeight,</span></span><br><span class="line"><span class="string">           deviceScaleFactor: window.devicePixelRatio,</span></span><br><span class="line"><span class="string">       &#125;</span></span><br><span class="line"><span class="string">   &#125;&#x27;&#x27;&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(dimensions)</span><br><span class="line">    <span class="keyword">await</span> browser.close()</span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<p><strong>调用evaluate方法执行了一些JavaScript，JavaScript 传入的是一个函数，使用 return 方法返回了网页的宽高、像素大小比率三个值，最后得到的是一个 JSON 格式的对象</strong></p>
<h3 id="12-1-详细用法"><a href="#12-1-详细用法" class="headerlink" title="12.1 详细用法"></a>12.1 详细用法</h3><p><strong>pyppeteer官方文档：</strong><a target="_blank" rel="noopener" href="https://miyakogi.github.io/pyppeteer/reference.html">https://miyakogi.github.io/pyppeteer/reference.html</a></p>
<h4 id="12-1-1-launch"><a href="#12-1-1-launch" class="headerlink" title="12.1.1 launch"></a>12.1.1 launch</h4><ul>
<li><p>无头模式</p>
<p>最常用的参数 headless，如果我们将它设置为 True 或者默认不设置它，在启动的时候我们是看不到任何界面的，如果把它设置为 False，那么在启动的时候就可以看到界面了，一般我们在调试的时候会把它设置为 False，在生产环境上就可以设置为 True，我们先尝试一下关闭 headless 模式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">await</span> launch(headless = <span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(<span class="number">100</span>)</span><br><span class="line">    </span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure></li>
<li><p>调试模式</p>
<p>另外我们还可以开启调试模式，比如在写爬虫的时候会经常需要分析网页结构还有网络请求，所以开启调试工具还是很有必要的，我们可以将 devtools 参数设置为 True，这样每开启一个界面就会弹出一个调试窗口，非常方便，示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   browser = <span class="keyword">await</span> launch(devtools=<span class="literal">True</span>)</span><br><span class="line">   page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">   <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line">   <span class="keyword">await</span> asyncio.sleep(<span class="number">100</span>)</span><br><span class="line"> </span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure></li>
<li><p>禁用提示条</p>
<p>这时候我们可以看到上面的一条提示：”Chrome 正受到自动测试软件的控制”，这个提示条有点烦，那该怎样关闭呢？这时候就需要用到 args 参数了，禁用操作如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">browser = <span class="keyword">await</span> launch(headless=<span class="literal">False</span>, args=[<span class="string">&#x27;--disable-infobars&#x27;</span>])</span><br></pre></td></tr></table></figure></li>
<li><p>防止检测<br>Pyppeteer 的 Page 对象有一个方法叫作 evaluateOnNewDocument，意思就是在每次加载网页的时候执行某个语句，所以这里我们可以执行一下将 WebDriver 隐藏的命令，改写如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   browser = <span class="keyword">await</span> launch(headless=<span class="literal">False</span>, args=[<span class="string">&#x27;--disable-infobars&#x27;</span>])</span><br><span class="line">   page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">   <span class="keyword">await</span> page.evaluateOnNewDocument(<span class="string">&#x27;Object.defineProperty(navigator, &quot;webdriver&quot;, &#123;get: () =&gt; undefined&#125;)&#x27;</span>)</span><br><span class="line">   <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://antispider1.scrape.center/&#x27;</span>)</span><br><span class="line">   <span class="keyword">await</span> asyncio.sleep(<span class="number">100</span>)</span><br><span class="line"> </span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure></li>
<li><p>页面大小设置</p>
<p>整个浏览器窗口比显示的内容窗口要大，这个是某些页面会出现的情况。</p>
<p>对于这种情况，我们通过设置窗口大小就可以解决，可以通过 Page 的 setViewport 方法设置，代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"> </span><br><span class="line">width, height = <span class="number">1366</span>, <span class="number">768</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   browser = <span class="keyword">await</span> launch(headless=<span class="literal">False</span>, args=[<span class="string">&#x27;--disable-infobars&#x27;</span>, <span class="string">f&#x27;--window-size=<span class="subst">&#123;width&#125;</span>,<span class="subst">&#123;height&#125;</span>&#x27;</span>])</span><br><span class="line">   page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">   <span class="keyword">await</span> page.setViewport(&#123;<span class="string">&#x27;width&#x27;</span>: width, <span class="string">&#x27;height&#x27;</span>: height&#125;)</span><br><span class="line">   <span class="keyword">await</span> page.evaluateOnNewDocument(<span class="string">&#x27;Object.defineProperty(navigator, &quot;webdriver&quot;, &#123;get: () =&gt; undefined&#125;)&#x27;</span>)</span><br><span class="line">   <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://antispider1.scrape.center/&#x27;</span>)</span><br><span class="line">   <span class="keyword">await</span> asyncio.sleep(<span class="number">100</span>)</span><br><span class="line"> </span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure></li>
<li><p>用户数据持久化<br>在启动的时候设置 userDataDir</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   browser = <span class="keyword">await</span> launch(headless=<span class="literal">False</span>, userDataDir=<span class="string">&#x27;./userdata&#x27;</span>, args=[<span class="string">&#x27;--disable-infobars&#x27;</span>])</span><br><span class="line">   page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">   <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://www.taobao.com&#x27;</span>)</span><br><span class="line">   <span class="keyword">await</span> asyncio.sleep(<span class="number">100</span>)</span><br><span class="line"> </span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="12-1-2-Browser"><a href="#12-1-2-Browser" class="headerlink" title="12.1.2 Browser"></a>12.1.2 Browser</h4><p>开启无痕模式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"> </span><br><span class="line">width, height = <span class="number">1200</span>, <span class="number">768</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   browser = <span class="keyword">await</span> launch(headless=<span class="literal">False</span>,</span><br><span class="line">                          args=[<span class="string">&#x27;--disable-infobars&#x27;</span>, <span class="string">f&#x27;--window-size=<span class="subst">&#123;width&#125;</span>,<span class="subst">&#123;height&#125;</span>&#x27;</span>])</span><br><span class="line">   context = <span class="keyword">await</span> browser.createIncognitoBrowserContext()</span><br><span class="line">   page = <span class="keyword">await</span> context.newPage()</span><br><span class="line">   <span class="keyword">await</span> page.setViewport(&#123;<span class="string">&#x27;width&#x27;</span>: width, <span class="string">&#x27;height&#x27;</span>: height&#125;)</span><br><span class="line">   <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line">   <span class="keyword">await</span> asyncio.sleep(<span class="number">100</span>)</span><br><span class="line"> </span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<h4 id="12-1-3-Page"><a href="#12-1-3-Page" class="headerlink" title="12.1.3 Page"></a>12.1.3 Page</h4><ul>
<li>选择器<br>Page 对象内置了一些用于选取节点的选择器方法，如 J 方法传入一个选择器 Selector，则能返回对应匹配的第一个节点，等价于 querySelector。如 JJ 方法则是返回符合 Selector 的列表，类似于 querySelectorAll。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   browser = <span class="keyword">await</span> launch()</span><br><span class="line">   page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">   <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://dynamic2.scrape.center/&#x27;</span>)</span><br><span class="line">   <span class="keyword">await</span> page.waitForSelector(<span class="string">&#x27;.item .name&#x27;</span>)</span><br><span class="line">   j_result1 = <span class="keyword">await</span> page.J(<span class="string">&#x27;.item .name&#x27;</span>)</span><br><span class="line">   j_result2 = <span class="keyword">await</span> page.querySelector(<span class="string">&#x27;.item .name&#x27;</span>)</span><br><span class="line">   jj_result1 = <span class="keyword">await</span> page.JJ(<span class="string">&#x27;.item .name&#x27;</span>)</span><br><span class="line">   jj_result2 = <span class="keyword">await</span> page.querySelectorAll(<span class="string">&#x27;.item .name&#x27;</span>)</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;J Result1:&#x27;</span>, j_result1)</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;J Result2:&#x27;</span>, j_result2)</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;JJ Result1:&#x27;</span>, jj_result1)</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;JJ Result2:&#x27;</span>, jj_result2)</span><br><span class="line">   <span class="keyword">await</span> browser.close()</span><br><span class="line"> </span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<ul>
<li>选项卡操作</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   browser = <span class="keyword">await</span> launch(headless=<span class="literal">False</span>)</span><br><span class="line">   page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">   <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line">   page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">   <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://www.bing.com&#x27;</span>)</span><br><span class="line">   pages = <span class="keyword">await</span> browser.pages()</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;Pages:&#x27;</span>, pages)</span><br><span class="line">   page1 = pages[<span class="number">1</span>]</span><br><span class="line">   <span class="keyword">await</span> page1.bringToFront()</span><br><span class="line">   <span class="keyword">await</span> asyncio.sleep(<span class="number">100</span>)</span><br><span class="line"> </span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<p>在这里我们启动了 Pyppeteer，然后调用了 newPage 方法新建了两个选项卡并访问了两个网站。那么如果我们要切换选项卡的话，只需要调用 pages 方法即可获取所有的页面，然后选一个页面调用其 bringToFront 方法即可切换到该页面对应的选项卡。</p>
<ul>
<li>常见操作</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   browser = <span class="keyword">await</span> launch(headless=<span class="literal">False</span>)</span><br><span class="line">   page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">   <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://dynamic1.scrape.center/&#x27;</span>)</span><br><span class="line">   <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://dynamic2.scrape.center/&#x27;</span>)</span><br><span class="line">   <span class="comment"># 后退</span></span><br><span class="line">   <span class="keyword">await</span> page.goBack()</span><br><span class="line">   <span class="comment"># 前进</span></span><br><span class="line">   <span class="keyword">await</span> page.goForward()</span><br><span class="line">   <span class="comment"># 刷新</span></span><br><span class="line">   <span class="keyword">await</span> page.reload()</span><br><span class="line">   <span class="comment"># 保存 PDF</span></span><br><span class="line">   <span class="keyword">await</span> page.pdf()</span><br><span class="line">   <span class="comment"># 截图</span></span><br><span class="line">   <span class="keyword">await</span> page.screenshot()</span><br><span class="line">   <span class="comment"># 设置页面 HTML</span></span><br><span class="line">   <span class="keyword">await</span> page.setContent(<span class="string">&#x27;&lt;h2&gt;Hello World&lt;/h2&gt;&#x27;</span>)</span><br><span class="line">   <span class="comment"># 设置 User-Agent</span></span><br><span class="line">   <span class="keyword">await</span> page.setUserAgent(<span class="string">&#x27;Python&#x27;</span>)</span><br><span class="line">   <span class="comment"># 设置 Headers</span></span><br><span class="line">   <span class="keyword">await</span> page.setExtraHTTPHeaders(headers=&#123;&#125;)</span><br><span class="line">   <span class="comment"># 关闭</span></span><br><span class="line">   <span class="keyword">await</span> page.close()</span><br><span class="line">   <span class="keyword">await</span> browser.close()</span><br><span class="line"> </span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<ul>
<li>点击</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   browser = <span class="keyword">await</span> launch(headless=<span class="literal">False</span>)</span><br><span class="line">   page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">   <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://dynamic2.scrape.center/&#x27;</span>)</span><br><span class="line">   <span class="keyword">await</span> page.waitForSelector(<span class="string">&#x27;.item .name&#x27;</span>)</span><br><span class="line">   <span class="keyword">await</span> page.click(<span class="string">&#x27;.item .name&#x27;</span>, options=&#123;</span><br><span class="line">       <span class="string">&#x27;button&#x27;</span>: <span class="string">&#x27;right&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;clickCount&#x27;</span>: <span class="number">1</span>,  <span class="comment"># 1 or 2</span></span><br><span class="line">       <span class="string">&#x27;delay&#x27;</span>: <span class="number">3000</span>,  <span class="comment"># 毫秒</span></span><br><span class="line">   &#125;)</span><br><span class="line">   <span class="keyword">await</span> browser.close()</span><br><span class="line"> </span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<p>这里 click 方法第一个参数就是选择器，即在哪里操作。第二个参数是几项配置：</p>
<p>button：鼠标按钮，分为 left、middle、right。</p>
<p>clickCount：点击次数，如双击、单击等。</p>
<p>delay：延迟点击。</p>
<ul>
<li>输入文本</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   browser = <span class="keyword">await</span> launch(headless=<span class="literal">False</span>)</span><br><span class="line">   page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">   <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://www.taobao.com&#x27;</span>)</span><br><span class="line">   <span class="comment"># 后退</span></span><br><span class="line">   <span class="keyword">await</span> page.<span class="built_in">type</span>(<span class="string">&#x27;#q&#x27;</span>, <span class="string">&#x27;iPad&#x27;</span>)</span><br><span class="line">   <span class="comment"># 关闭</span></span><br><span class="line">   <span class="keyword">await</span> asyncio.sleep(<span class="number">10</span>)</span><br><span class="line">   <span class="keyword">await</span> browser.close()</span><br><span class="line"> </span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<ul>
<li>获取信息</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   browser = <span class="keyword">await</span> launch(headless=<span class="literal">False</span>)</span><br><span class="line">   page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">   <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://dynamic2.scrape.center/&#x27;</span>)</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;HTML:&#x27;</span>, <span class="keyword">await</span> page.content())</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;Cookies:&#x27;</span>, <span class="keyword">await</span> page.cookies())</span><br><span class="line">   <span class="keyword">await</span> browser.close()</span><br><span class="line"> </span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<h3 id="12-2-Pyppeteer爬取实战"><a href="#12-2-Pyppeteer爬取实战" class="headerlink" title="12.2 Pyppeteer爬取实战"></a>12.2 Pyppeteer爬取实战</h3><h3 id="12-2-1-爬取列表页"><a href="#12-2-1-爬取列表页" class="headerlink" title="12.2.1 爬取列表页"></a>12.2.1 爬取列表页</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line">browser,tab = <span class="literal">None</span>,<span class="literal">None</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">init</span>():</span><br><span class="line">    <span class="keyword">global</span> browser,tab</span><br><span class="line">    browser = <span class="keyword">await</span> launch(headless = HEADLESS,args=[<span class="string">&#x27;--disable-infobars&#x27;</span>,<span class="string">f&#x27;--window-size=<span class="subst">&#123;WINDOW_WIDTH&#125;</span>,<span class="subst">&#123;WINDOW_HEIGHT&#125;</span>&#x27;</span>)</span><br><span class="line">    tab = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">    <span class="keyword">await</span> tab.setViewport(&#123;<span class="string">&#x27;width&#x27;</span>:WINDOW_WIDTH,<span class="string">&#x27;height&#x27;</span>:WINDOW_HEIGHT&#125;)                                                     </span><br></pre></td></tr></table></figure>

<h4 id="12-2-2-定义通用爬取方法"><a href="#12-2-2-定义通用爬取方法" class="headerlink" title="12.2.2  定义通用爬取方法"></a>12.2.2  定义通用爬取方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyppeteer.errors <span class="keyword">import</span> TimeoutError</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_api</span>(<span class="params">url,selector</span>):</span><br><span class="line">    logging.info(<span class="string">&quot;scrpaing %s&quot;</span>,url)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">await</span> tab.goto(url)</span><br><span class="line">        <span class="keyword">await</span> tab.waitForSelector(selector,options = &#123;<span class="string">&#x27;timeout&#x27;</span>:TIMEOUT*<span class="number">1000</span>&#125;)</span><br><span class="line">    <span class="keyword">except</span> TimeoutError:</span><br><span class="line">        logging.error(<span class="string">&#x27;error occurred while scraping %s&#x27;</span>, url, exc_info=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h4 id="12-2-3-爬取列表页的方法"><a href="#12-2-3-爬取列表页的方法" class="headerlink" title="12.2.3 爬取列表页的方法"></a>12.2.3 爬取列表页的方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_index</span>(<span class="params">page</span>):</span><br><span class="line">    url = INDEX_URL.<span class="built_in">format</span>(page=page)</span><br><span class="line">    <span class="keyword">await</span> scrape_api(url,<span class="string">&quot;.item .name&quot;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="12-2-4-定义解析列表页的方法"><a href="#12-2-4-定义解析列表页的方法" class="headerlink" title="12.2.4 定义解析列表页的方法"></a>12.2.4 定义解析列表页的方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">parse_index</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">await</span> tab.querySelectorALLEval(<span class="string">&quot;.item .name&quot;</span>,<span class="string">&#x27;nodes =&gt; nodes.map(node =&gt; node.href)&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>这里我们调用了 querySelectorAllEval 方法，它接收两个参数，第一个参数是 selector，代表要选择的节点对应的 CSS 选择器；第二个参数是 pageFunction，代表的是要执行的 JavaScript 方法，这里需要传入的是一段 JavaScript 字符串，整个方法的作用是选择 selector 对应的节点，然后对这些节点通过 pageFunction 定义的逻辑抽取出对应的结果并返回。</p>
<p>所以这里第一个参数 selector 就传入电影名称对应的节点，其实是超链接 a 节点。由于提取结果有多个，所以这里 JavaScript 对应的 pageFunction 输入参数就是 nodes，输出结果是调用了 map 方法得到每个 node，然后调用 node 的 href 属性即可。这样返回结果就是当前列表页的所有电影的详情页 URL 组成的列表了。</p>
<h4 id="12-2-5-串联调用"><a href="#12-2-5-串联调用" class="headerlink" title="12.2.5 串联调用"></a>12.2.5 串联调用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio </span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">await</span> init()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,TOTAL_PAGE+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">await</span> scrape_index(page)</span><br><span class="line">            detail_urls = <span class="keyword">await</span> parse_index()</span><br><span class="line">            logging.info(<span class="string">&#x27;detail_urls %s&#x27;</span>, detail_urls)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="keyword">await</span> browser.close()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<h4 id="12-2-6-爬取详情页"><a href="#12-2-6-爬取详情页" class="headerlink" title="12.2.6 爬取详情页"></a>12.2.6 爬取详情页</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">scrape_detail</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">await</span> scrape_page(url,<span class="string">&quot;h2&quot;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="12-2-7-提取详情信息"><a href="#12-2-7-提取详情信息" class="headerlink" title="12.2.7 提取详情信息"></a>12.2.7 提取详情信息</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">parse_detail</span>():</span><br><span class="line">   url = tab.url</span><br><span class="line">   name = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;h2&#x27;</span>, <span class="string">&#x27;node =&gt; node.innerText&#x27;</span>)</span><br><span class="line">   categories = <span class="keyword">await</span> tab.querySelectorAllEval(<span class="string">&#x27;.categories button span&#x27;</span>, <span class="string">&#x27;nodes =&gt; nodes.map(node =&gt; node.innerText)&#x27;</span>)</span><br><span class="line">   cover = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;.cover&#x27;</span>, <span class="string">&#x27;node =&gt; node.src&#x27;</span>)</span><br><span class="line">   score = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;.score&#x27;</span>, <span class="string">&#x27;node =&gt; node.innerText&#x27;</span>)</span><br><span class="line">   drama = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;.drama p&#x27;</span>, <span class="string">&#x27;node =&gt; node.innerText&#x27;</span>)</span><br><span class="line">   <span class="keyword">return</span> &#123;</span><br><span class="line">       <span class="string">&#x27;url&#x27;</span>: url,</span><br><span class="line">       <span class="string">&#x27;name&#x27;</span>: name,</span><br><span class="line">       <span class="string">&#x27;categories&#x27;</span>: categories,</span><br><span class="line">       <span class="string">&#x27;cover&#x27;</span>: cover,</span><br><span class="line">       <span class="string">&#x27;score&#x27;</span>: score,</span><br><span class="line">       <span class="string">&#x27;drama&#x27;</span>: drama</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<h4 id="12-2-8-主方法的实现"><a href="#12-2-8-主方法的实现" class="headerlink" title="12.2.8 主方法的实现"></a>12.2.8 主方法的实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   <span class="keyword">await</span> init()</span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">       <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, TOTAL_PAGE + <span class="number">1</span>):</span><br><span class="line">           <span class="keyword">await</span> scrape_index(page)</span><br><span class="line">           detail_urls = <span class="keyword">await</span> parse_index()</span><br><span class="line">           <span class="keyword">for</span> detail_url <span class="keyword">in</span> detail_urls:</span><br><span class="line">               <span class="keyword">await</span> scrape_detail(detail_url)</span><br><span class="line">               detail_data = <span class="keyword">await</span> parse_detail()</span><br><span class="line">               logging.info(<span class="string">&#x27;data %s&#x27;</span>, detail_data)</span><br><span class="line">   <span class="keyword">finally</span>:</span><br><span class="line">       <span class="keyword">await</span> browser.close()</span><br></pre></td></tr></table></figure>



<h2 id="14-代理的基本原理和用法"><a href="#14-代理的基本原理和用法" class="headerlink" title="14.代理的基本原理和用法"></a>14.代理的基本原理和用法</h2><h3 id="14-1-基本原理"><a href="#14-1-基本原理" class="headerlink" title="14.1 基本原理"></a>14.1 基本原理</h3><p>代理实际上指的就是代理服务器，英文叫作 proxy server，它的功能是代理网络用户去获取网络信息。形象地说，它是网络信息的中转站。在我们正常请求一个网站时，是发送了请求给 Web 服务器，Web 服务器把响应传回给我们。如果设置了代理服务器，实际上就是在本机和服务器之间搭建了一个桥，此时本机不是直接向 Web 服务器发起请求，而是向代理服务器发出请求，请求会发送给代理服务器，然后由代理服务器再发送给 Web 服务器，接着由代理服务器再把 Web 服务器返回的响应转发给本机。这样我们同样可以正常访问网页，但这个过程中 Web 服务器识别出的真实 IP 就不再是我们本机的 IP 了，就成功实现了 IP 伪装，这就是代理的基本原理。</p>
<h3 id="14-2代理的作用"><a href="#14-2代理的作用" class="headerlink" title="14.2代理的作用"></a>14.2代理的作用</h3><ul>
<li>突破自身 IP 访问限制，访问一些平时不能访问的站点。</li>
<li>访问一些单位或团体内部资源，如使用教育网内地址段免费代理服务器，就可以用于对教育网开放的各类 FTP 下载上传，以及各类资料查询共享等服务。</li>
<li>提高访问速度，通常代理服务器都设置一个较大的硬盘缓冲区，当有外界的信息通过时，也将其保存到缓冲区中，当其他用户再访问相同的信息时， 则直接由缓冲区中取出信息，传给用户，以提高访问速度。</li>
<li>隐藏真实 IP，上网者也可以通过这种方法隐藏自己的 IP，免受攻击，对于爬虫来说，我们用代理就是为了隐藏自身 IP，防止自身的 IP 被封锁。</li>
</ul>
<h3 id="14-3-代理分类"><a href="#14-3-代理分类" class="headerlink" title="14.3 代理分类"></a>14.3 代理分类</h3><h4 id="14-3-1根据协议区分"><a href="#14-3-1根据协议区分" class="headerlink" title="14.3.1根据协议区分"></a>14.3.1根据协议区分</h4><ul>
<li>FTP 代理服务器，主要用于访问 FTP 服务器，一般有上传、下载以及缓存功能，端口一般为 21、2121 等。</li>
<li>HTTP 代理服务器，主要用于访问网页，一般有内容过滤和缓存功能，端口一般为 80、8080、3128 等。</li>
<li>SSL/TLS 代理，主要用于访问加密网站，一般有 SSL 或 TLS 加密功能（最高支持 128 位加密强度），端口一般为 443。</li>
<li>RTSP 代理，主要用于 Realplayer 访问 Real 流媒体服务器，一般有缓存功能，端口一般为 554。</li>
<li>Telnet 代理，主要用于 telnet 远程控制（黑客入侵计算机时常用于隐藏身份），端口一般为 23。</li>
<li>POP3/SMTP 代理，主要用于 POP3/SMTP 方式收发邮件，一般有缓存功能，端口一般为 110/25。</li>
<li>SOCKS 代理，只是单纯传递数据包，不关心具体协议和用法，所以速度快很多，一般有缓存功能，端口一般为 1080。SOCKS 代理协议又分为 SOCKS4 和 SOCKS5，SOCKS4 协议只支持 TCP，而 SOCKS5 协议支持 TCP 和 UDP，还支持各种身份验证机制、服务器端域名解析等。简单来说，SOCK4 能做到的 SOCKS5 都可以做到，但 SOCKS5 能做到的 SOCK4 不一定能做到。</li>
</ul>
<h4 id="14-3-2-根据匿名程度区分"><a href="#14-3-2-根据匿名程度区分" class="headerlink" title="14.3.2 根据匿名程度区分"></a>14.3.2 根据匿名程度区分</h4><ul>
<li>高度匿名代理，高度匿名代理会将数据包原封不动的转发，在服务端看来就好像真的是一个普通客户端在访问，而记录的 IP 是代理服务器的 IP。</li>
<li>普通匿名代理，普通匿名代理会在数据包上做一些改动，服务端上有可能发现这是个代理服务器，也有一定几率追查到客户端的真实 IP。代理服务器通常会加入的 HTTP 头有 HTTP_VIA 和 HTTP_X_FORWARDED_FOR。</li>
<li>透明代理，透明代理不但改动了数据包，还会告诉服务器客户端的真实 IP。这种代理除了能用缓存技术提高浏览速度，能用内容过滤提高安全性之外，并无其他显著作用，最常见的例子是内网中的硬件防火墙。</li>
<li>间谍代理，间谍代理指组织或个人创建的，用于记录用户传输的数据，然后进行研究、监控等目的的代理服务器。</li>
</ul>
<h4 id="14-3-3-常见代理类型"><a href="#14-3-3-常见代理类型" class="headerlink" title="14.3.3 常见代理类型"></a>14.3.3 常见代理类型</h4><ul>
<li>使用网上的免费代理，最好使用高匿代理，使用前抓取下来筛选一下可用代理，也可以进一步维护一个代理池。</li>
<li>使用付费代理服务，互联网上存在许多代理商，可以付费使用，质量比免费代理好很多。</li>
<li>ADSL 拨号，拨一次号换一次 IP，稳定性高，也是一种比较有效的解决方案。</li>
<li>蜂窝代理，即用 4G 或 5G 网卡等制作的代理，由于蜂窝网络用作代理的情形较少，因此整体被封锁的几率会较低，但搭建蜂窝代理的成本较高。</li>
</ul>
<h3 id="14-4-代理设置"><a href="#14-4-代理设置" class="headerlink" title="14.4 代理设置"></a>14.4 代理设置</h3><h4 id="14-4-1-requests-代理设置"><a href="#14-4-1-requests-代理设置" class="headerlink" title="14.4.1 requests 代理设置"></a>14.4.1 requests 代理设置</h4><p>只需要传入proxies参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">proxy = <span class="string">&quot;127.0.0.1:7890&quot;</span></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">&quot;http&quot;</span>:<span class="string">&quot;http://&quot;</span> + proxy</span><br><span class="line">    <span class="string">&quot;https&quot;</span>:<span class="string">&quot;https://&quot;</span> + proxy</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">try</span> : </span><br><span class="line">    response = requests.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>, proxies=proxies)</span><br><span class="line">    <span class="built_in">print</span>(response.text)</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.ConnectionError <span class="keyword">as</span> e:</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;Error&#x27;</span>, e.args)</span><br></pre></td></tr></table></figure>

<p>如果代理需要认证，同样在代理的前面加上用户名密码即可，代理的写法就变成如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proxy = <span class="string">&#x27;username:password@127.0.0.1:7890&#x27;</span></span><br></pre></td></tr></table></figure>

<p>如果使用SOCKS代理，则可以使用如下方法来设置：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">proxy = <span class="string">&#x27;127.0.0.1:7891&#x27;</span></span><br><span class="line">proxies = &#123;</span><br><span class="line">   <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;socks5://&#x27;</span> + proxy,</span><br><span class="line">   <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;socks5://&#x27;</span> + proxy</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">   response = requests.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>, proxies=proxies)</span><br><span class="line">   <span class="built_in">print</span>(response.text)</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.ConnectionError <span class="keyword">as</span> e:</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;Error&#x27;</span>, e.args)</span><br></pre></td></tr></table></figure>

<h4 id="14-4-2-Selenium设置代理"><a href="#14-4-2-Selenium设置代理" class="headerlink" title="14.4.2 Selenium设置代理"></a>14.4.2 Selenium设置代理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">proxy = <span class="string">&#x27;127.0.0.1:7890&#x27;</span></span><br><span class="line">options = webdriver.ChromeOptions()</span><br><span class="line">options.add_argument(<span class="string">&#x27;--proxy-server=http://&#x27;</span> + proxy)	</span><br><span class="line">browser = webdriver.Chrome(options=options)</span><br><span class="line">browser.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(browser.page_source)</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure>

<p>SOCKS 代理的设置也比较简单，把对应的协议修改为 socks5 即可，如无密码认证的代理设置方法为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">proxy = <span class="string">&#x27;127.0.0.1:7891&#x27;</span></span><br><span class="line">options = webdriver.ChromeOptions()</span><br><span class="line">options.add_argument(<span class="string">&#x27;--proxy-server=socks5://&#x27;</span> + proxy)</span><br><span class="line">browser = webdriver.Chrome(options=options)</span><br><span class="line">browser.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(browser.page_source)</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure>

<h4 id="14-4-3-aiohttp设置代理"><a href="#14-4-3-aiohttp设置代理" class="headerlink" title="14.4.3 aiohttp设置代理"></a>14.4.3 aiohttp设置代理</h4><p>对于 aiohttp 来说，我们可以通过 proxy 参数直接设置即可，HTTP 代理设置如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"></span><br><span class="line">proxy = <span class="string">&#x27;http://127.0.0.1:7890&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">       <span class="keyword">async</span> <span class="keyword">with</span> session.get(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>, proxy=proxy) <span class="keyword">as</span> response:</span><br><span class="line">           <span class="built_in">print</span>(<span class="keyword">await</span> response.text())</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<p>如果代理有用户名密码，像 requests 一样，把 proxy 修改为如下内容：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proxy = <span class="string">&#x27;http://username:password@127.0.0.1:7890&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="14-4-4-Pyppeteer设置代理"><a href="#14-4-4-Pyppeteer设置代理" class="headerlink" title="14.4.4 Pyppeteer设置代理"></a>14.4.4 Pyppeteer设置代理</h4><p>对于 Pyppeteer 来说，由于其默认使用的是类似 Chrome 的 Chromium 浏览器，因此设置方法和 Selenium 的 Chrome 是一样的，如 HTTP 无认证代理设置方法都是通过 args 来设置，实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"></span><br><span class="line">proxy = <span class="string">&#x27;127.0.0.1:7890&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">   browser = <span class="keyword">await</span> launch(&#123;<span class="string">&#x27;args&#x27;</span>: [<span class="string">&#x27;--proxy-server=http://&#x27;</span> + proxy], <span class="string">&#x27;headless&#x27;</span>: <span class="literal">False</span>&#125;)</span><br><span class="line">   page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">   <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://httpbin.org/get&#x27;</span>)</span><br><span class="line">   <span class="built_in">print</span>(<span class="keyword">await</span> page.content())</span><br><span class="line">   <span class="keyword">await</span> browser.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<p>对于 SOCKS 代理，也是一样的，只需要将协议修改为 socks5 即可</p>
<h2 id="15-代理池的搭建和使用"><a href="#15-代理池的搭建和使用" class="headerlink" title="15.代理池的搭建和使用"></a>15.代理池的搭建和使用</h2><h3 id="15-1-代理池的目标"><a href="#15-1-代理池的目标" class="headerlink" title="15.1 代理池的目标"></a>15.1 代理池的目标</h3><ul>
<li>基本模块分为 4 块：存储模块、获取模块、检测模块、接口模块。</li>
<li>存储模块：负责存储抓取下来的代理。首先要保证代理不重复，要标识代理的可用情况，还要动态实时处理每个代理，所以一种比较高效和方便的存储方式就是使用 Redis 的 Sorted Set，即有序集合。</li>
<li>获取模块：需要定时在各大代理网站抓取代理。代理可以是免费公开代理也可以是付费代理，代理的形式都是 IP 加端口，此模块尽量从不同来源获取，尽量抓取高匿代理，抓取成功之后将可用代理保存到数据库中。</li>
<li>检测模块：需要定时检测数据库中的代理。这里需要设置一个检测链接，最好是爬取哪个网站就检测哪个网站，这样更加有针对性，如果要做一个通用型的代理，那可以设置百度等链接来检测。另外，我们需要标识每一个代理的状态，如设置分数标识，100 分代表可用，分数越少代表越不可用。检测一次，如果代理可用，我们可以将分数标识立即设置为 100 满分，也可以在原基础上加 1 分；如果代理不可用，可以将分数标识减 1 分，当分数减到一定阈值后，代理就直接从数据库移除。通过这样的标识分数，我们就可以辨别代理的可用情况，选用的时候会更有针对性。</li>
<li>接口模块：需要用 API 来提供对外服务的接口。其实我们可以直接连接数据库来获取对应的数据，但是这样就需要知道数据库的连接信息，并且要配置连接，而比较安全和方便的方式就是提供一个 Web API 接口，我们通过访问接口即可拿到可用代理。另外，由于可用代理可能有多个，那么我们可以设置一个随机返回某个可用代理的接口，这样就能保证每个可用代理都可以取到，实现负载均衡。</li>
</ul>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220516173222805.png" alt="image-20220516173222805"></p>
<p>代理池分为四个模块：存储模块，检测模块，获取模块，接口模块</p>
<ul>
<li>存储模块使用 Redis 的有序集合，用来做代理的去重和状态标识，同时它也是中心模块和基础模块，将其他模块串联起来。</li>
<li>获取模块定时从代理网站获取代理，将获取的代理传递给存储模块，并保存到数据库。</li>
<li>检测模块定时通过存储模块获取所有代理，并对代理进行检测，根据不同的检测结果对代理设置不同的标识。</li>
<li>接口模块通过 Web API 提供服务接口，接口通过连接数据库并通过 Web 形式返回可用的代理。</li>
</ul>
<h3 id="15-3-代理池的实现"><a href="#15-3-代理池的实现" class="headerlink" title="15.3 代理池的实现"></a>15.3 代理池的实现</h3><p>代理分数设置如下：</p>
<ul>
<li>分数 100 为可用，检测器会定时循环检测每个代理可用情况，一旦检测到有可用的代理就立即置为 100，检测到不可用就将分数减 1，分数减至 0 后代理移除。</li>
<li>新获取的代理的分数为 10，如果测试可行，分数立即置为 100，不可行则分数减 1，分数减至 0 后代理移除。</li>
</ul>
<p>这只是一种解决方案，当然可能还有更合理的方案。之所以设置此方案有如下几个原因。</p>
<ul>
<li>在检测到代理可用时，分数立即置为 100，这样可以保证所有可用代理有更大的机会被获取到。你可能会问，为什么不将分数加 1 而是直接设为最高 100 呢？设想一下，有的代理是从各大免费公开代理网站获取的，常常一个代理并没有那么稳定，平均 5 次请求可能有两次成功，3 次失败，如果按照这种方式来设置分数，那么这个代理几乎不可能达到一个高的分数，也就是说即便它有时是可用的，但是筛选的分数最高，那这样的代理几乎不可能被取到。如果想追求代理稳定性，可以用上述方法，这种方法可确保分数最高的代理一定是最稳定可用的。所以，这里我们采取 “可用即设置 100” 的方法，确保只要可用的代理都可以被获取到。</li>
<li>在检测到代理不可用时，分数减 1，分数减至 0 后，代理移除。这样一个有效代理如果要被移除需要连续不断失败 100 次，也就是说当一个可用代理如果尝试了 100 次都失败了，就一直减分直到移除，一旦成功就重新置回 100。尝试机会越多，则这个代理拯救回来的机会越多，这样就不容易将曾经的一个可用代理丢弃，因为代理不可用的原因很可能是网络繁忙或者其他人用此代理请求太过频繁，所以在这里将分数为 100。</li>
<li>新获取的代理的分数设置为 10，代理如果不可用，分数就减 1，分数减到 0，代理就移除，如果代理可用，分数就置为 100。由于很多代理是从免费网站获取的，所以新获取的代理无效的比例非常高，可能可用的代理不足 10%。所以在这里我们将分数设置为 10，检测的机会没有可用代理的 100 次那么多，这也可以适当减少开销。</li>
</ul>
<p>存储模块的实现代码：<a target="_blank" rel="noopener" href="https://github.com/Python3WebSpider/ProxyPool/tree/master/proxypool/storages">https://github.com/Python3WebSpider/ProxyPool/tree/master/proxypool/storages</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Whoami</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2022/12/06/python%E7%88%AC%E8%99%AB/">http://example.com/2022/12/06/python%E7%88%AC%E8%99%AB/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/12/06/HTML%E5%AD%A6%E4%B9%A0/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">HTML学习笔记</div></div></a></div><div class="next-post pull-right"><a href="/2022/12/06/hello-world/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Hello World</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Whoami</div><div class="author-info__description">Whoami的个人博客，主要用于分享自己平时学习的经验与资料整理。</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">3</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Whoami0831" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:295235173@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="toc-number">1.</span> <span class="toc-text">1.多线程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%A4%9A%E8%BF%9B%E7%A8%8B"><span class="toc-number">2.</span> <span class="toc-text">2.多进程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E5%A4%9A%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%90%AB%E4%B9%89"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 多进程的含义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Python-%E5%A4%9A%E8%BF%9B%E7%A8%8B%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 Python 多进程的优势</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E5%A4%9A%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 多进程的实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E7%BB%A7%E6%89%BFProcess%E7%B1%BB"><span class="toc-number">2.4.</span> <span class="toc-text">2.4 继承Process类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B"><span class="toc-number">2.5.</span> <span class="toc-text">2.5 守护进程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-6%E8%BF%9B%E7%A8%8B%E7%AD%89%E5%BE%85"><span class="toc-number">2.6.</span> <span class="toc-text">2.6进程等待</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-7-%E7%BB%88%E6%AD%A2%E8%BF%9B%E7%A8%8B"><span class="toc-number">2.7.</span> <span class="toc-text">2.7 终止进程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-8-%E8%BF%9B%E7%A8%8B%E4%BA%92%E6%96%A5%E9%94%81"><span class="toc-number">2.8.</span> <span class="toc-text">2.8 进程互斥锁</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-9-%E4%BF%A1%E5%8F%B7%E9%87%8F"><span class="toc-number">2.9.</span> <span class="toc-text">2.9 信号量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-10-%E8%BF%9B%E7%A8%8B%E6%B1%A0"><span class="toc-number">2.10.</span> <span class="toc-text">2.10 进程池</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-11-%E7%AE%80%E5%8C%96%E8%BF%9B%E7%A8%8B%E6%B1%A0%EF%BC%8Cmap%E6%96%B9%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">2.11.</span> <span class="toc-text">2.11 简化进程池，map方法的使用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-requests%E5%BA%93"><span class="toc-number">3.</span> <span class="toc-text">3.requests库</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-respone%E5%AF%B9%E8%B1%A1%E5%8F%AF%E8%B0%83%E7%94%A8%E6%96%B9%E6%B3%95"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 respone对象可调用方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E6%8A%93%E5%8F%96%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%95%B0%E6%8D%AE"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 抓取二进制数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E5%93%8D%E5%BA%94"><span class="toc-number">3.3.</span> <span class="toc-text">3.3 响应</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95"><span class="toc-number">3.4.</span> <span class="toc-text">3.4 高级用法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-1-%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0"><span class="toc-number">3.4.1.</span> <span class="toc-text">3.4.1 文件上传</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-2-Cookies"><span class="toc-number">3.4.2.</span> <span class="toc-text">3.4.2 Cookies</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-3-Session%E7%BB%B4%E6%8C%81"><span class="toc-number">3.4.3.</span> <span class="toc-text">3.4.3 Session维持</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-4-SSL%E8%AF%81%E4%B9%A6%E9%AA%8C%E8%AF%81"><span class="toc-number">3.4.4.</span> <span class="toc-text">3.4.4 SSL证书验证</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-5-%E8%B6%85%E6%97%B6%E8%AE%BE%E7%BD%AE"><span class="toc-number">3.4.5.</span> <span class="toc-text">3.4.5 超时设置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-6-%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81"><span class="toc-number">3.4.6.</span> <span class="toc-text">3.4.6 身份认证</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-7-%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE"><span class="toc-number">3.4.7.</span> <span class="toc-text">3.4.7 代理设置</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Requests-PyQuery-PyMongo-%E5%9F%BA%E6%9C%AC%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98"><span class="toc-number">4.</span> <span class="toc-text">4. Requests + PyQuery + PyMongo 基本案例实战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E5%BA%93%E5%BC%95%E5%85%A5%E5%8F%8A%E5%9F%BA%E7%A1%80%E5%8F%98%E9%87%8F%E5%AE%9A%E4%B9%89"><span class="toc-number">4.1.</span> <span class="toc-text">4.1 库引入及基础变量定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E9%A1%B5%E9%9D%A2%E7%9A%84%E7%88%AC%E5%8F%96%E6%96%B9%E6%B3%95"><span class="toc-number">4.2.</span> <span class="toc-text">4.2 实现一个页面的爬取方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E5%AE%9A%E4%B9%89%E5%88%97%E8%A1%A8%E9%A1%B5%E7%9A%84%E7%88%AC%E5%8F%96%E6%96%B9%E6%B3%95"><span class="toc-number">4.3.</span> <span class="toc-text">4.3 定义列表页的爬取方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E8%A7%A3%E6%9E%90%E5%88%97%E8%A1%A8%E9%A1%B5"><span class="toc-number">4.4.</span> <span class="toc-text">4.4 解析列表页</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-%E8%A7%A3%E6%9E%90%E8%AF%A6%E6%83%85%E9%A1%B5"><span class="toc-number">4.5.</span> <span class="toc-text">4.5 解析详情页</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-6-%E4%BF%9D%E5%AD%98%E5%88%B0MongoDB"><span class="toc-number">4.6.</span> <span class="toc-text">4.6 保存到MongoDB</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-7%E5%B0%86%E6%95%B0%E6%8D%AE%E4%BF%9D%E5%AD%98%E5%88%B0MongoDB"><span class="toc-number">4.7.</span> <span class="toc-text">4.7将数据保存到MongoDB</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-8-%E5%AE%9E%E7%8E%B0main%E6%96%B9%E6%B3%95"><span class="toc-number">4.8.</span> <span class="toc-text">4.8 实现main方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-9-%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%8A%A0%E9%80%9F"><span class="toc-number">4.9.</span> <span class="toc-text">4.9 多进程加速</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Ajax%E5%8E%9F%E7%90%86%E5%92%8C%E8%A7%A3%E6%9E%90"><span class="toc-number">5.</span> <span class="toc-text">5.Ajax原理和解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E4%BB%80%E4%B9%88%E6%98%AFAjax"><span class="toc-number">5.1.</span> <span class="toc-text">5.1 什么是Ajax</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-number">5.2.</span> <span class="toc-text">5.2 基本原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-Ajax%E7%88%AC%E5%8F%96%E6%A1%88%E4%BE%8B"><span class="toc-number">5.3.</span> <span class="toc-text">5.3 Ajax爬取案例</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-1-%E5%AE%9E%E7%8E%B0%E9%80%9A%E7%94%A8%E7%9A%84%E7%88%AC%E5%8F%96%E6%96%B9%E6%B3%95"><span class="toc-number">5.3.1.</span> <span class="toc-text">5.3.1 实现通用的爬取方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-2-%E5%AE%9A%E4%B9%89%E7%88%AC%E5%8F%96%E5%88%97%E8%A1%A8%E9%A1%B5%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">5.3.2.</span> <span class="toc-text">5.3.2 定义爬取列表页的方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-3-%E7%88%AC%E5%8F%96%E8%AF%A6%E6%83%85%E9%A1%B5"><span class="toc-number">5.3.3.</span> <span class="toc-text">5.3.3 爬取详情页</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-4-%E5%88%86%E6%9E%90%E8%AF%A6%E6%83%85%E6%95%B0%E6%8D%AE"><span class="toc-number">5.3.4.</span> <span class="toc-text">5.3.4 分析详情数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-5-%E5%B0%86%E6%95%B0%E6%8D%AE%E4%BF%9D%E5%AD%98%E5%88%B0MongoDB"><span class="toc-number">5.3.5.</span> <span class="toc-text">5.3.5 将数据保存到MongoDB</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-6-%E5%AE%9E%E7%8E%B0%E4%B8%BB%E7%A8%8B%E5%BA%8F"><span class="toc-number">5.3.6.</span> <span class="toc-text">5.3.6 实现主程序</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-7-%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%8A%A0%E9%80%9F"><span class="toc-number">5.3.7.</span> <span class="toc-text">5.3.7 多进程加速</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-selenium-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-number">6.</span> <span class="toc-text">6.selenium 基本使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E5%A3%B0%E6%98%8E%E6%B5%8F%E8%A7%88%E5%99%A8%E5%AF%B9%E8%B1%A1"><span class="toc-number">6.1.</span> <span class="toc-text">6.1 声明浏览器对象</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-%E8%AE%BF%E9%97%AE%E9%A1%B5%E9%9D%A2"><span class="toc-number">6.2.</span> <span class="toc-text">6.2 访问页面</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3%E6%9F%A5%E6%89%BE%E8%8A%82%E7%82%B9"><span class="toc-number">6.3.</span> <span class="toc-text">6.3查找节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-4-%E8%8A%82%E7%82%B9%E4%BA%A4%E4%BA%92"><span class="toc-number">6.4.</span> <span class="toc-text">6.4 节点交互</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-5-%E5%8A%A8%E4%BD%9C%E9%93%BE"><span class="toc-number">6.5.</span> <span class="toc-text">6.5 动作链</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-6-%E6%89%A7%E8%A1%8CJAVASCRIPT"><span class="toc-number">6.6.</span> <span class="toc-text">6.6 执行JAVASCRIPT</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-7-%E8%8E%B7%E5%8F%96%E8%8A%82%E7%82%B9%E4%BF%A1%E6%81%AF"><span class="toc-number">6.7.</span> <span class="toc-text">6.7 获取节点信息</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#6-7-1-%E8%8E%B7%E5%BE%97%E5%B1%9E%E6%80%A7"><span class="toc-number">6.7.1.</span> <span class="toc-text">6.7.1 获得属性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-7-2-%E8%8E%B7%E5%8F%96%E6%96%87%E6%9C%AC%E5%80%BC"><span class="toc-number">6.7.2.</span> <span class="toc-text">6.7.2 获取文本值</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-7-3-%E8%8E%B7%E5%8F%96ID%EF%BC%8C%E4%BD%8D%E7%BD%AE%EF%BC%8C%E6%A0%87%E7%AD%BE%E5%90%8D%EF%BC%8C%E5%A4%A7%E5%B0%8F"><span class="toc-number">6.7.3.</span> <span class="toc-text">6.7.3 获取ID，位置，标签名，大小</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-7-4-%E5%88%87%E6%8D%A2Frame"><span class="toc-number">6.7.4.</span> <span class="toc-text">6.7.4 切换Frame</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-8-%E5%BB%B6%E6%97%B6%E7%AD%89%E5%BE%85"><span class="toc-number">6.8.</span> <span class="toc-text">6.8 延时等待</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#6-8-1-%E9%9A%90%E5%BC%8F%E7%AD%89%E5%BE%85"><span class="toc-number">6.8.1.</span> <span class="toc-text">6.8.1 隐式等待</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-8-2-%E6%98%BE%E7%A4%BA%E7%AD%89%E5%BE%85"><span class="toc-number">6.8.2.</span> <span class="toc-text">6.8.2 显示等待</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-8-3-%E6%89%80%E6%9C%89%E7%9A%84%E7%AD%89%E5%BE%85%E6%9D%A1%E4%BB%B6"><span class="toc-number">6.8.3.</span> <span class="toc-text">6.8.3 所有的等待条件</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-9-%E5%89%8D%E8%BF%9B%E5%90%8E%E9%80%80"><span class="toc-number">6.9.</span> <span class="toc-text">6.9 前进后退</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-10-Cookies"><span class="toc-number">6.10.</span> <span class="toc-text">6.10 Cookies</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-11-%E9%80%89%E9%A1%B9%E5%8D%A1%E7%AE%A1%E7%90%86"><span class="toc-number">6.11.</span> <span class="toc-text">6.11 选项卡管理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-12-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86"><span class="toc-number">6.12.</span> <span class="toc-text">6.12 异常处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-13-%E5%8F%8D%E5%B1%8F%E8%94%BD"><span class="toc-number">6.13.</span> <span class="toc-text">6.13 反屏蔽</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-14-%E6%97%A0%E5%A4%B4%E6%A8%A1%E5%BC%8F"><span class="toc-number">6.14.</span> <span class="toc-text">6.14 无头模式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-selenium-%E7%88%AC%E5%8F%96%E6%A1%88%E4%BE%8B"><span class="toc-number">7.</span> <span class="toc-text">7. selenium 爬取案例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E6%8A%93%E5%8F%96%E5%88%97%E8%A1%A8%E9%A1%B5"><span class="toc-number">7.1.</span> <span class="toc-text">7.1 抓取列表页</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-MongoDB%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE"><span class="toc-number">7.2.</span> <span class="toc-text">7.2 MongoDB基本配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E9%80%9A%E7%94%A8%E7%9A%84%E7%88%AC%E5%8F%96%E6%96%B9%E6%B3%95"><span class="toc-number">7.3.</span> <span class="toc-text">7.3 定义一个通用的爬取方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-4-%E7%88%AC%E5%8F%96%E5%88%97%E8%A1%A8%E9%A1%B5%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">7.4.</span> <span class="toc-text">7.4 爬取列表页的方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-5-%E8%BF%9B%E8%A1%8C%E5%88%97%E8%A1%A8%E9%A1%B5%E7%9A%84%E8%A7%A3%E6%9E%90-%EF%BC%88%E8%8E%B7%E5%8F%96%E6%89%80%E6%9C%89%E8%AF%A6%E6%83%85%E9%A1%B5%E7%9A%84%E7%9B%B8%E5%AF%B9%E8%B7%AF%E5%BE%84%EF%BC%89"><span class="toc-number">7.5.</span> <span class="toc-text">7.5 进行列表页的解析    （获取所有详情页的相对路径）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-6%E7%88%AC%E5%8F%96%E8%AF%A6%E6%83%85%E9%A1%B5"><span class="toc-number">7.6.</span> <span class="toc-text">7.6爬取详情页</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-7-%E6%8F%90%E5%8F%96%E8%AF%A6%E6%83%85%E9%A1%B5"><span class="toc-number">7.7.</span> <span class="toc-text">7.7 提取详情页</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-8-%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE"><span class="toc-number">7.8.</span> <span class="toc-text">7.8 存储数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-9-main%E6%96%B9%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">7.9.</span> <span class="toc-text">7.9 main方法的实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-10-%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%8A%A0%E9%80%9F"><span class="toc-number">7.10.</span> <span class="toc-text">7.10 多进程加速</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB"><span class="toc-number">8.</span> <span class="toc-text">8.异步爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-%E9%98%BB%E5%A1%9E"><span class="toc-number">8.1.</span> <span class="toc-text">8.1 阻塞</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-%E9%9D%9E%E9%98%BB%E5%A1%9E"><span class="toc-number">8.2.</span> <span class="toc-text">8.2 非阻塞</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-3-%E5%90%8C%E6%AD%A5"><span class="toc-number">8.3.</span> <span class="toc-text">8.3 同步</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-4-%E5%BC%82%E6%AD%A5"><span class="toc-number">8.4.</span> <span class="toc-text">8.4 异步</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-5-%E5%8D%8F%E7%A8%8B"><span class="toc-number">8.5.</span> <span class="toc-text">8.5 协程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-6-%E5%8D%8F%E7%A8%8B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">8.6.</span> <span class="toc-text">8.6 协程基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-7%E5%AE%9A%E4%B9%89%E5%8D%8F%E7%A8%8B"><span class="toc-number">8.7.</span> <span class="toc-text">8.7定义协程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-8-%E7%BB%91%E5%AE%9A%E5%9B%9E%E8%B0%83"><span class="toc-number">8.8.</span> <span class="toc-text">8.8 绑定回调</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-9-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%8D%8F%E7%A8%8B"><span class="toc-number">8.9.</span> <span class="toc-text">8.9 多任务协程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-10-%E5%8D%8F%E7%A8%8B%E5%AE%9E%E7%8E%B0"><span class="toc-number">8.10.</span> <span class="toc-text">8.10 协程实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%E4%BD%BF%E7%94%A8aiohttp"><span class="toc-number">9.</span> <span class="toc-text">9.使用aiohttp</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-aiohttp"><span class="toc-number">9.1.</span> <span class="toc-text">9.1 aiohttp</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-%E5%9F%BA%E6%9C%AC%E5%AE%9E%E4%BE%8B"><span class="toc-number">9.2.</span> <span class="toc-text">9.2 基本实例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-post%E6%95%B0%E6%8D%AE"><span class="toc-number">9.3.</span> <span class="toc-text">9.3 post数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-%E5%93%8D%E5%BA%94%E5%AD%97%E6%AE%B5"><span class="toc-number">9.4.</span> <span class="toc-text">9.4 响应字段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-5-%E8%B6%85%E6%97%B6%E8%AE%BE%E7%BD%AE"><span class="toc-number">9.5.</span> <span class="toc-text">9.5 超时设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-6-%E5%B9%B6%E5%8F%91%E9%99%90%E5%88%B6"><span class="toc-number">9.6.</span> <span class="toc-text">9.6 并发限制</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-aiohttp%E7%88%AC%E5%8F%96%E5%AE%9E%E6%88%98"><span class="toc-number">10.</span> <span class="toc-text">10.aiohttp爬取实战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-1-%E9%A1%B5%E9%9D%A2%E5%88%86%E6%9E%90"><span class="toc-number">10.1.</span> <span class="toc-text">10.1 页面分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-%E5%AE%9E%E7%8E%B0%E6%80%9D%E8%B7%AF"><span class="toc-number">10.2.</span> <span class="toc-text">10.2 实现思路</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-3-%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE"><span class="toc-number">10.3.</span> <span class="toc-text">10.3 基本配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-4-%E5%AE%9A%E4%B9%89%E9%80%9A%E7%94%A8%E7%88%AC%E5%8F%96%E6%96%B9%E5%BC%8F"><span class="toc-number">10.4.</span> <span class="toc-text">10.4 定义通用爬取方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-5-%E6%8A%93%E5%8F%96%E5%88%97%E8%A1%A8%E9%A1%B5"><span class="toc-number">10.5.</span> <span class="toc-text">10.5 抓取列表页</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-6-%E8%8E%B7%E5%8F%96%E8%AF%A6%E6%83%85%E9%A1%B5id"><span class="toc-number">10.6.</span> <span class="toc-text">10.6 获取详情页id</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-7%E5%AE%9A%E4%B9%89%E7%88%AC%E5%8F%96%E8%AF%A6%E6%83%85%E9%A1%B5%E5%B9%B6%E5%AD%98%E5%82%A8%E6%96%B9%E6%B3%95"><span class="toc-number">10.7.</span> <span class="toc-text">10.7定义爬取详情页并存储方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-8-%E5%AE%9A%E4%B9%89%E5%AD%98%E5%82%A8%E6%96%B9%E6%B3%95"><span class="toc-number">10.8.</span> <span class="toc-text">10.8 定义存储方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-9-main%E6%96%B9%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">10.9.</span> <span class="toc-text">10.9 main方法的实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-%E5%A4%9A%E7%BA%BF%E7%A8%8B%EF%BC%8C%E5%A4%9A%E8%BF%9B%E7%A8%8B%EF%BC%8C%E5%8D%8F%E7%A8%8B%E5%BC%82%E6%AD%A5"><span class="toc-number">11.</span> <span class="toc-text">11.多线程，多进程，协程异步</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-Pyppeteer"><span class="toc-number">12.</span> <span class="toc-text">12.Pyppeteer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#12-1-%E8%AF%A6%E7%BB%86%E7%94%A8%E6%B3%95"><span class="toc-number">12.1.</span> <span class="toc-text">12.1 详细用法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#12-1-1-launch"><span class="toc-number">12.1.1.</span> <span class="toc-text">12.1.1 launch</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-1-2-Browser"><span class="toc-number">12.1.2.</span> <span class="toc-text">12.1.2 Browser</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-1-3-Page"><span class="toc-number">12.1.3.</span> <span class="toc-text">12.1.3 Page</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-2-Pyppeteer%E7%88%AC%E5%8F%96%E5%AE%9E%E6%88%98"><span class="toc-number">12.2.</span> <span class="toc-text">12.2 Pyppeteer爬取实战</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-2-1-%E7%88%AC%E5%8F%96%E5%88%97%E8%A1%A8%E9%A1%B5"><span class="toc-number">12.3.</span> <span class="toc-text">12.2.1 爬取列表页</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#12-2-2-%E5%AE%9A%E4%B9%89%E9%80%9A%E7%94%A8%E7%88%AC%E5%8F%96%E6%96%B9%E6%B3%95"><span class="toc-number">12.3.1.</span> <span class="toc-text">12.2.2  定义通用爬取方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-2-3-%E7%88%AC%E5%8F%96%E5%88%97%E8%A1%A8%E9%A1%B5%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">12.3.2.</span> <span class="toc-text">12.2.3 爬取列表页的方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-2-4-%E5%AE%9A%E4%B9%89%E8%A7%A3%E6%9E%90%E5%88%97%E8%A1%A8%E9%A1%B5%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">12.3.3.</span> <span class="toc-text">12.2.4 定义解析列表页的方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-2-5-%E4%B8%B2%E8%81%94%E8%B0%83%E7%94%A8"><span class="toc-number">12.3.4.</span> <span class="toc-text">12.2.5 串联调用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-2-6-%E7%88%AC%E5%8F%96%E8%AF%A6%E6%83%85%E9%A1%B5"><span class="toc-number">12.3.5.</span> <span class="toc-text">12.2.6 爬取详情页</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-2-7-%E6%8F%90%E5%8F%96%E8%AF%A6%E6%83%85%E4%BF%A1%E6%81%AF"><span class="toc-number">12.3.6.</span> <span class="toc-text">12.2.7 提取详情信息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-2-8-%E4%B8%BB%E6%96%B9%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">12.3.7.</span> <span class="toc-text">12.2.8 主方法的实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-%E4%BB%A3%E7%90%86%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E5%92%8C%E7%94%A8%E6%B3%95"><span class="toc-number">13.</span> <span class="toc-text">14.代理的基本原理和用法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#14-1-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-number">13.1.</span> <span class="toc-text">14.1 基本原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14-2%E4%BB%A3%E7%90%86%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">13.2.</span> <span class="toc-text">14.2代理的作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14-3-%E4%BB%A3%E7%90%86%E5%88%86%E7%B1%BB"><span class="toc-number">13.3.</span> <span class="toc-text">14.3 代理分类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#14-3-1%E6%A0%B9%E6%8D%AE%E5%8D%8F%E8%AE%AE%E5%8C%BA%E5%88%86"><span class="toc-number">13.3.1.</span> <span class="toc-text">14.3.1根据协议区分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#14-3-2-%E6%A0%B9%E6%8D%AE%E5%8C%BF%E5%90%8D%E7%A8%8B%E5%BA%A6%E5%8C%BA%E5%88%86"><span class="toc-number">13.3.2.</span> <span class="toc-text">14.3.2 根据匿名程度区分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#14-3-3-%E5%B8%B8%E8%A7%81%E4%BB%A3%E7%90%86%E7%B1%BB%E5%9E%8B"><span class="toc-number">13.3.3.</span> <span class="toc-text">14.3.3 常见代理类型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14-4-%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE"><span class="toc-number">13.4.</span> <span class="toc-text">14.4 代理设置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#14-4-1-requests-%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE"><span class="toc-number">13.4.1.</span> <span class="toc-text">14.4.1 requests 代理设置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#14-4-2-Selenium%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86"><span class="toc-number">13.4.2.</span> <span class="toc-text">14.4.2 Selenium设置代理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#14-4-3-aiohttp%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86"><span class="toc-number">13.4.3.</span> <span class="toc-text">14.4.3 aiohttp设置代理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#14-4-4-Pyppeteer%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86"><span class="toc-number">13.4.4.</span> <span class="toc-text">14.4.4 Pyppeteer设置代理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15-%E4%BB%A3%E7%90%86%E6%B1%A0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%92%8C%E4%BD%BF%E7%94%A8"><span class="toc-number">14.</span> <span class="toc-text">15.代理池的搭建和使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#15-1-%E4%BB%A3%E7%90%86%E6%B1%A0%E7%9A%84%E7%9B%AE%E6%A0%87"><span class="toc-number">14.1.</span> <span class="toc-text">15.1 代理池的目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-3-%E4%BB%A3%E7%90%86%E6%B1%A0%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">14.2.</span> <span class="toc-text">15.3 代理池的实现</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/12/06/HTML%E5%AD%A6%E4%B9%A0/" title="HTML学习笔记"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HTML学习笔记"/></a><div class="content"><a class="title" href="/2022/12/06/HTML%E5%AD%A6%E4%B9%A0/" title="HTML学习笔记">HTML学习笔记</a><time datetime="2022-12-06T14:38:56.000Z" title="Created 2022-12-06 22:38:56">2022-12-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/06/python%E7%88%AC%E8%99%AB/" title="HTML学习笔记"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HTML学习笔记"/></a><div class="content"><a class="title" href="/2022/12/06/python%E7%88%AC%E8%99%AB/" title="HTML学习笔记">HTML学习笔记</a><time datetime="2022-12-06T14:38:56.000Z" title="Created 2022-12-06 22:38:56">2022-12-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/06/hello-world/" title="Hello World"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hello World"/></a><div class="content"><a class="title" href="/2022/12/06/hello-world/" title="Hello World">Hello World</a><time datetime="2022-12-06T09:52:11.089Z" title="Created 2022-12-06 17:52:11">2022-12-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Whoami</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>